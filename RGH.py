import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import re
import pandas as pd
import random
import os
from typing import List, Tuple, Dict, Set
import threading
import numpy as np
import plotly.graph_objects as go
import plotly.offline as pyo
import tempfile
import webbrowser
from pathlib import Path

class DocumentAnalyzerApp:
    def __init__(self, root):
        self.root = root
        self.root.title("ğŸ“š æ–‡æ¡£å¥å­åˆ†æç³»ç»Ÿ")
        self.root.geometry("1200x800")
        
        # å­˜å‚¨æ•°æ®
        self.sentences = []
        self.analysis_data = []
        self.words_data = []
        self.words_value_data = []
        self.char_mapping = {}  # å­—ç¬¦æ˜ å°„è¡¨ï¼šå­—ç¬¦ -> åœ¨ä¸åŒå¥å­ä¸­çš„æ•°å€¼åˆ—è¡¨
        self.relation_data = []  # å­—ç¬¦è¯è¯­å…³ç³»åˆ†ææ•°æ®
        self.stable_mappings = {}  # ç¨³å®šçš„æ˜ å°„å…³ç³»
        
        self.setup_ui()
    
    def setup_ui(self):
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®ç½‘æ ¼æƒé‡
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        main_frame.rowconfigure(3, weight=1)
        
        # æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="ğŸ“š æ–‡æ¡£å¥å­åˆ†æç³»ç»Ÿ", 
                               font=("Arial", 16, "bold"))
        title_label.grid(row=0, column=0, columnspan=3, pady=(0, 20))
        
        # æ–‡ä»¶é€‰æ‹©åŒºåŸŸ
        file_frame = ttk.LabelFrame(main_frame, text="æ–‡ä»¶é€‰æ‹©", padding="10")
        file_frame.grid(row=1, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 10))
        file_frame.columnconfigure(1, weight=1)
        
        ttk.Label(file_frame, text="æ–‡æ¡£æ–‡ä»¶:").grid(row=0, column=0, sticky=tk.W)
        
        self.file_path_var = tk.StringVar()
        ttk.Entry(file_frame, textvariable=self.file_path_var, width=60).grid(row=0, column=1, padx=(5, 5), sticky=(tk.W, tk.E))
        
        ttk.Button(file_frame, text="æµè§ˆ...", command=self.browse_file).grid(row=0, column=2, padx=(5, 0))
        ttk.Button(file_frame, text="æå–å¥å­", command=self.extract_sentences).grid(row=0, column=3, padx=(5, 0))
        
        # ç»Ÿè®¡ä¿¡æ¯åŒºåŸŸ
        stats_frame = ttk.LabelFrame(main_frame, text="ç»Ÿè®¡ä¿¡æ¯", padding="10")
        stats_frame.grid(row=2, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.stats_text = tk.StringVar()
        self.stats_text.set("æ€»å¥å­æ•°: 0\nå¹³å‡é•¿åº¦: 0.0\næœ€é•¿å¥å­: 0\næœ€çŸ­å¥å­: 0")
        ttk.Label(stats_frame, textvariable=self.stats_text, justify=tk.LEFT).grid(row=0, column=0, sticky=tk.W)
        
        # åˆ›å»ºç¬”è®°æœ¬ï¼ˆé€‰é¡¹å¡ï¼‰
        self.notebook = ttk.Notebook(main_frame)
        self.notebook.grid(row=3, column=0, columnspan=3, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(10, 0))
        
        # æå–ç»“æœæ ‡ç­¾é¡µ
        self.extract_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.extract_tab, text="æå–ç»“æœ")
        self.setup_extract_tab()
        
        # å­—ç¬¦åˆ†ææ ‡ç­¾é¡µ
        self.analysis_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.analysis_tab, text="å­—ç¬¦ç»„åˆåˆ†æ")
        self.setup_analysis_tab()
        
        # å­—ç¬¦æ˜ å°„è¡¨æ ‡ç­¾é¡µ
        self.char_mapping_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.char_mapping_tab, text="å­—ç¬¦æ˜ å°„è¡¨")
        self.setup_char_mapping_tab()
        
        # è¯è¯­åˆ†ææ ‡ç­¾é¡µ
        self.words_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.words_tab, text="è¯è¯­åˆ†æ")
        self.setup_words_tab()
        
        # è¯è¯­æ•°å€¼åˆ†é…æ ‡ç­¾é¡µ
        self.words_value_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.words_value_tab, text="è¯è¯­æ•°å€¼åˆ†é…")
        self.setup_words_value_tab()
        
        # è¯¦ç»†ç¤ºä¾‹æ ‡ç­¾é¡µ
        self.example_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.example_tab, text="è¯¦ç»†ç¤ºä¾‹")
        self.setup_example_tab()
        
        # å›¾è¡¨åˆ†ææ ‡ç­¾é¡µ
        self.chart_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.chart_tab, text="å›¾è¡¨åˆ†æ")
        self.setup_chart_tab()
        
        # å­—ç¬¦æ€ç»´ç½‘ç»œæ ‡ç­¾é¡µ
        self.flow_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.flow_tab, text="å­—ç¬¦æ€ç»´ç½‘ç»œ")
        self.setup_flow_tab()
        
        # å¥å­è¿˜åŸæµ‹è¯•æ ‡ç­¾é¡µ
        self.restore_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.restore_tab, text="å¥å­è¿˜åŸæµ‹è¯•")
        self.setup_restore_tab()
        
        # å­—ç¬¦è¯è¯­å…³ç³»åˆ†ææ ‡ç­¾é¡µ
        self.relation_tab = ttk.Frame(self.notebook, padding="10")
        self.notebook.add(self.relation_tab, text="å­—ç¬¦è¯è¯­å…³ç³»åˆ†æ")
        self.setup_relation_tab()
        
        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(main_frame, mode='indeterminate')
        self.progress.grid(row=4, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=(10, 0))
    
    def setup_extract_tab(self):
        self.extract_tab.columnconfigure(0, weight=1)
        self.extract_tab.rowconfigure(0, weight=1)
        
        # åˆ›å»ºè¡¨æ ¼æ¡†æ¶
        table_frame = ttk.Frame(self.extract_tab)
        table_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # åˆ›å»ºæ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # åˆ›å»ºTreeviewè¡¨æ ¼
        self.extract_tree = ttk.Treeview(table_frame, columns=('åºå·', 'å¥å­', 'é•¿åº¦'), 
                                        show='headings', 
                                        yscrollcommand=scrollbar_y.set,
                                        xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        self.extract_tree.heading('åºå·', text='åºå·')
        self.extract_tree.heading('å¥å­', text='å¥å­')
        self.extract_tree.heading('é•¿åº¦', text='é•¿åº¦')
        
        self.extract_tree.column('åºå·', width=80, anchor=tk.CENTER)
        self.extract_tree.column('å¥å­', width=600, anchor=tk.W)
        self.extract_tree.column('é•¿åº¦', width=80, anchor=tk.CENTER)
        
        self.extract_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # é…ç½®æ»šåŠ¨æ¡
        scrollbar_y.config(command=self.extract_tree.yview)
        scrollbar_x.config(command=self.extract_tree.xview)
    
    def setup_analysis_tab(self):
        # åˆ†ææ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.analysis_tab)
        control_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="èµ·å§‹åºå·:").grid(row=0, column=0, padx=(0, 5))
        self.start_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.start_seq_var, width=10).grid(row=0, column=1, padx=(0, 15))
        
        ttk.Label(control_frame, text="ç»“æŸåºå·:").grid(row=0, column=2, padx=(0, 5))
        self.end_seq_var = tk.StringVar(value="10")
        ttk.Entry(control_frame, textvariable=self.end_seq_var, width=10).grid(row=0, column=3, padx=(0, 15))
        
        ttk.Button(control_frame, text="ç”Ÿæˆåˆ†æ", command=self.generate_analysis).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜ç»“æœ", command=self.save_analysis).grid(row=0, column=5)
        
        # åˆ†æç»“æœè¡¨æ ¼
        self.analysis_tab.columnconfigure(0, weight=1)
        self.analysis_tab.rowconfigure(1, weight=1)
        
        table_frame = ttk.Frame(self.analysis_tab)
        table_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # æ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Treeviewè¡¨æ ¼
        self.analysis_tree = ttk.Treeview(table_frame, 
                                         columns=('åºå·', 'å¥å­', 'é•¿åº¦', 'å­—ç¬¦ç»„åˆ', 'æ•°å€¼', 'æ€»å’ŒéªŒè¯'), 
                                         show='headings',
                                         yscrollcommand=scrollbar_y.set,
                                         xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        columns_config = {
            'åºå·': 80, 'å¥å­': 200, 'é•¿åº¦': 60, 
            'å­—ç¬¦ç»„åˆ': 300, 'æ•°å€¼': 200, 'æ€»å’ŒéªŒè¯': 80
        }
        
        for col, width in columns_config.items():
            self.analysis_tree.heading(col, text=col)
            self.analysis_tree.column(col, width=width, anchor=tk.CENTER)
        
        self.analysis_tree.column('å¥å­', anchor=tk.W)
        self.analysis_tree.column('å­—ç¬¦ç»„åˆ', anchor=tk.W)
        self.analysis_tree.column('æ•°å€¼', anchor=tk.W)
        
        self.analysis_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar_y.config(command=self.analysis_tree.yview)
        scrollbar_x.config(command=self.analysis_tree.xview)
    
    def setup_char_mapping_tab(self):
        """è®¾ç½®å­—ç¬¦æ˜ å°„è¡¨æ ‡ç­¾é¡µ"""
        self.char_mapping_tab.columnconfigure(0, weight=1)
        self.char_mapping_tab.rowconfigure(1, weight=1)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.char_mapping_tab)
        control_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Button(control_frame, text="ç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨", command=self.generate_char_mapping).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜æ˜ å°„è¡¨", command=self.save_char_mapping).grid(row=0, column=1, padx=(0, 10))
        
        # å­—ç¬¦æ˜ å°„è¡¨ç»Ÿè®¡ä¿¡æ¯
        self.char_mapping_stats_var = tk.StringVar()
        self.char_mapping_stats_var.set("æ€»å­—ç¬¦æ•°: 0\næ€»æ˜ å°„æ•°: 0\næœ€å¤šæ•°å€¼å­—ç¬¦: 0")
        ttk.Label(control_frame, textvariable=self.char_mapping_stats_var, justify=tk.LEFT).grid(row=0, column=2, padx=(20, 0))
        
        # å­—ç¬¦æ˜ å°„è¡¨ç»“æœ
        table_frame = ttk.Frame(self.char_mapping_tab)
        table_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # æ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Treeviewè¡¨æ ¼
        self.char_mapping_tree = ttk.Treeview(table_frame, 
                                            columns=('åºå·', 'å­—ç¬¦', 'æ•°å€¼åˆ—è¡¨', 'å‡ºç°æ¬¡æ•°'), 
                                            show='headings',
                                            yscrollcommand=scrollbar_y.set,
                                            xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        columns_config = {
            'åºå·': 60, 'å­—ç¬¦': 80, 'æ•°å€¼åˆ—è¡¨': 400, 'å‡ºç°æ¬¡æ•°': 80
        }
        
        for col, width in columns_config.items():
            self.char_mapping_tree.heading(col, text=col)
            self.char_mapping_tree.column(col, width=width, anchor=tk.CENTER)
        
        self.char_mapping_tree.column('æ•°å€¼åˆ—è¡¨', anchor=tk.W)
        
        self.char_mapping_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar_y.config(command=self.char_mapping_tree.yview)
        scrollbar_x.config(command=self.char_mapping_tree.xview)
    
    def setup_words_tab(self):
        # è¯è¯­åˆ†ææ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.words_tab)
        control_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="èµ·å§‹åºå·:").grid(row=0, column=0, padx=(0, 5))
        self.words_start_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.words_start_seq_var, width=10).grid(row=0, column=1, padx=(0, 15))
        
        ttk.Label(control_frame, text="ç»“æŸåºå·:").grid(row=0, column=2, padx=(0, 5))
        self.words_end_seq_var = tk.StringVar(value="10")
        ttk.Entry(control_frame, textvariable=self.words_end_seq_var, width=10).grid(row=0, column=3, padx=(0, 15))
        
        ttk.Button(control_frame, text="åˆ†è¯åˆ†æ", command=self.generate_words_analysis).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜è¯è¯­", command=self.save_words_analysis).grid(row=0, column=5)
        
        # è¯è¯­ç»Ÿè®¡ä¿¡æ¯
        self.words_stats_var = tk.StringVar()
        self.words_stats_var.set("æ€»è¯è¯­æ•°: 0\nå”¯ä¸€è¯è¯­æ•°: 0\nå¹³å‡è¯è¯­é•¿åº¦: 0.0")
        ttk.Label(control_frame, textvariable=self.words_stats_var, justify=tk.LEFT).grid(row=0, column=6, padx=(20, 0))
        
        # è¯è¯­ç»“æœè¡¨æ ¼
        self.words_tab.columnconfigure(0, weight=1)
        self.words_tab.rowconfigure(1, weight=1)
        
        table_frame = ttk.Frame(self.words_tab)
        table_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # æ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Treeviewè¡¨æ ¼
        self.words_tree = ttk.Treeview(table_frame, 
                                      columns=('åºå·', 'è¯è¯­', 'å­—ç¬¦é•¿åº¦', 'è¯é¢‘', 'å¥å­æ¥æº'), 
                                      show='headings',
                                      yscrollcommand=scrollbar_y.set,
                                      xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        columns_config = {
            'åºå·': 60, 'è¯è¯­': 150, 'å­—ç¬¦é•¿åº¦': 80, 'è¯é¢‘': 60, 'å¥å­æ¥æº': 300
        }
        
        for col, width in columns_config.items():
            self.words_tree.heading(col, text=col)
            self.words_tree.column(col, width=width, anchor=tk.CENTER)
        
        self.words_tree.column('è¯è¯­', anchor=tk.W)
        self.words_tree.column('å¥å­æ¥æº', anchor=tk.W)
        
        self.words_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar_y.config(command=self.words_tree.yview)
        scrollbar_x.config(command=self.words_tree.xview)
    
    def setup_words_value_tab(self):
        # è¯è¯­æ•°å€¼åˆ†é…æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.words_value_tab)
        control_frame.grid(row=0, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="èµ·å§‹åºå·:").grid(row=0, column=0, padx=(0, 5))
        self.words_value_start_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.words_value_start_seq_var, width=10).grid(row=0, column=1, padx=(0, 15))
        
        ttk.Label(control_frame, text="ç»“æŸåºå·:").grid(row=0, column=2, padx=(0, 5))
        self.words_value_end_seq_var = tk.StringVar(value="10")
        ttk.Entry(control_frame, textvariable=self.words_value_end_seq_var, width=10).grid(row=0, column=3, padx=(0, 15))
        
        ttk.Button(control_frame, text="ç”Ÿæˆè¯è¯­æ•°å€¼åˆ†é…", command=self.generate_words_value_analysis).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜ç»“æœ", command=self.save_words_value_analysis).grid(row=0, column=5)
        
        # è¯è¯­æ•°å€¼åˆ†é…ç»“æœè¡¨æ ¼
        self.words_value_tab.columnconfigure(0, weight=1)
        self.words_value_tab.rowconfigure(1, weight=1)
        
        table_frame = ttk.Frame(self.words_value_tab)
        table_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # æ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Treeviewè¡¨æ ¼
        self.words_value_tree = ttk.Treeview(table_frame, 
                                           columns=('åºå·', 'å¥å­', 'è¯è¯­æ•°é‡', 'è¯è¯­ç»„åˆ', 'æ•°å€¼', 'æ€»å’ŒéªŒè¯'), 
                                           show='headings',
                                           yscrollcommand=scrollbar_y.set,
                                           xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        columns_config = {
            'åºå·': 80, 'å¥å­': 200, 'è¯è¯­æ•°é‡': 80, 
            'è¯è¯­ç»„åˆ': 300, 'æ•°å€¼': 200, 'æ€»å’ŒéªŒè¯': 80
        }
        
        for col, width in columns_config.items():
            self.words_value_tree.heading(col, text=col)
            self.words_value_tree.column(col, width=width, anchor=tk.CENTER)
        
        self.words_value_tree.column('å¥å­', anchor=tk.W)
        self.words_value_tree.column('è¯è¯­ç»„åˆ', anchor=tk.W)
        self.words_value_tree.column('æ•°å€¼', anchor=tk.W)
        
        self.words_value_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar_y.config(command=self.words_value_tree.yview)
        scrollbar_x.config(command=self.words_value_tree.xview)
    
    def setup_example_tab(self):
        self.example_tab.columnconfigure(0, weight=1)
        self.example_tab.rowconfigure(1, weight=1)
        
        # ç¤ºä¾‹ä¿¡æ¯
        info_frame = ttk.Frame(self.example_tab)
        info_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        self.example_info_var = tk.StringVar()
        self.example_info_var.set("è¯·å…ˆç”Ÿæˆåˆ†æç»“æœ")
        ttk.Label(info_frame, textvariable=self.example_info_var, justify=tk.LEFT).grid(row=0, column=0, sticky=tk.W)
        
        # ç¤ºä¾‹è¡¨æ ¼
        table_frame = ttk.Frame(self.example_tab)
        table_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.example_tree = ttk.Treeview(table_frame, columns=('å­—ç¬¦', 'æ•°å€¼'), 
                                        show='headings',
                                        yscrollcommand=scrollbar_y.set)
        
        self.example_tree.heading('å­—ç¬¦', text='å­—ç¬¦')
        self.example_tree.heading('æ•°å€¼', text='æ•°å€¼')
        self.example_tree.column('å­—ç¬¦', width=100, anchor=tk.CENTER)
        self.example_tree.column('æ•°å€¼', width=100, anchor=tk.CENTER)
        
        self.example_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        scrollbar_y.config(command=self.example_tree.yview)
    
    def setup_chart_tab(self):
        """è®¾ç½®å›¾è¡¨åˆ†ææ ‡ç­¾é¡µ"""
        self.chart_tab.columnconfigure(0, weight=1)
        self.chart_tab.rowconfigure(1, weight=1)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.chart_tab)
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="é€‰æ‹©å¥å­åºå·:").grid(row=0, column=0, padx=(0, 5))
        self.chart_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.chart_seq_var, width=10).grid(row=0, column=1, padx=(0, 15))
        
        ttk.Button(control_frame, text="ç”Ÿæˆå­—ç¬¦æ•°å€¼å›¾", command=self.generate_char_chart).grid(row=0, column=2, padx=(0, 10))
        ttk.Button(control_frame, text="ç”Ÿæˆå¥å­é•¿åº¦åˆ†å¸ƒ", command=self.generate_length_chart).grid(row=0, column=3, padx=(0, 10))
        ttk.Button(control_frame, text="ç”Ÿæˆè¯è¯­é¢‘ç‡å›¾", command=self.generate_word_freq_chart).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜å›¾è¡¨", command=self.save_chart).grid(row=0, column=5)
        
        # å›¾è¡¨æ˜¾ç¤ºåŒºåŸŸ
        self.chart_frame = ttk.Frame(self.chart_tab)
        self.chart_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        self.chart_frame.columnconfigure(0, weight=1)
        self.chart_frame.rowconfigure(0, weight=1)
        
        # çŠ¶æ€æ ‡ç­¾
        self.chart_status_var = tk.StringVar()
        self.chart_status_var.set("è¯·ç”Ÿæˆå›¾è¡¨")
        ttk.Label(self.chart_frame, textvariable=self.chart_status_var).grid(row=0, column=0, sticky=(tk.W, tk.E))
    
    def setup_flow_tab(self):
        """è®¾ç½®å­—ç¬¦æ€ç»´ç½‘ç»œæ ‡ç­¾é¡µ"""
        self.flow_tab.columnconfigure(0, weight=1)
        self.flow_tab.rowconfigure(1, weight=1)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.flow_tab)
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Button(control_frame, text="ç”Ÿæˆæ€ç»´ç½‘ç»œ", command=self.generate_mind_network).grid(row=0, column=0, padx=(0, 10))
        ttk.Button(control_frame, text="åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€", command=self.open_network_in_browser).grid(row=0, column=1, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜ç½‘ç»œå›¾", command=self.save_flow_chart).grid(row=0, column=2, padx=(0, 10))
        
        # çŠ¶æ€æ ‡ç­¾
        self.flow_status_var = tk.StringVar()
        self.flow_status_var.set("è¯·ç”Ÿæˆæ€ç»´ç½‘ç»œ")
        ttk.Label(control_frame, textvariable=self.flow_status_var).grid(row=0, column=3, padx=(20, 0))
        
        # ç½‘ç»œå›¾æ˜¾ç¤ºåŒºåŸŸ
        self.flow_frame = ttk.Frame(self.flow_tab)
        self.flow_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        self.flow_frame.columnconfigure(0, weight=1)
        self.flow_frame.rowconfigure(0, weight=1)
        
        # çŠ¶æ€æ ‡ç­¾
        ttk.Label(self.flow_frame, text="æ€ç»´ç½‘ç»œå°†åœ¨æµè§ˆå™¨ä¸­æ˜¾ç¤ºï¼Œè¯·ç‚¹å‡»'åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€'æŸ¥çœ‹").grid(row=0, column=0, sticky=(tk.W, tk.E))
    
    def setup_restore_tab(self):
        """è®¾ç½®å¥å­è¿˜åŸæµ‹è¯•æ ‡ç­¾é¡µ"""
        self.restore_tab.columnconfigure(0, weight=1)
        self.restore_tab.rowconfigure(1, weight=1)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.restore_tab)
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="æµ‹è¯•æ¨¡å¼:").grid(row=0, column=0, padx=(0, 5))
        
        self.test_mode_var = tk.StringVar(value="random")
        test_mode_frame = ttk.Frame(control_frame)
        test_mode_frame.grid(row=0, column=1, padx=(0, 15))
        
        ttk.Radiobutton(test_mode_frame, text="éšæœºæµ‹è¯•", variable=self.test_mode_var, value="random").grid(row=0, column=0, padx=(0, 10))
        ttk.Radiobutton(test_mode_frame, text="æŒ‡å®šå¥å­", variable=self.test_mode_var, value="specific").grid(row=0, column=1, padx=(0, 10))
        
        ttk.Label(control_frame, text="å¥å­åºå·:").grid(row=0, column=2, padx=(0, 5))
        self.restore_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.restore_seq_var, width=10).grid(row=0, column=3, padx=(0, 15))
        
        ttk.Button(control_frame, text="ç”Ÿæˆæµ‹è¯•", command=self.generate_restore_test).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="æ£€æŸ¥ç­”æ¡ˆ", command=self.check_restore_answer).grid(row=0, column=5, padx=(0, 10))
        ttk.Button(control_frame, text="æ˜¾ç¤ºç­”æ¡ˆ", command=self.show_restore_answer).grid(row=0, column=6)
        
        # æµ‹è¯•ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        self.restore_tab.columnconfigure(0, weight=1)
        self.restore_tab.rowconfigure(1, weight=1)
        
        # åˆ›å»ºä¸Šä¸‹åˆ†æ 
        paned_window = ttk.PanedWindow(self.restore_tab, orient=tk.VERTICAL)
        paned_window.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # ä¸ŠåŠéƒ¨åˆ†ï¼šæµ‹è¯•é¢˜ç›®
        test_frame = ttk.LabelFrame(paned_window, text="æµ‹è¯•é¢˜ç›®", padding="10")
        paned_window.add(test_frame, weight=1)
        
        test_frame.columnconfigure(0, weight=1)
        test_frame.rowconfigure(1, weight=1)
        
        ttk.Label(test_frame, text="è¯·æ ¹æ®å­—ç¬¦æ˜ å°„å…³ç³»å’Œæ€ç»´ç½‘ç»œï¼Œè¿˜åŸä»¥ä¸‹å¥å­:").grid(row=0, column=0, sticky=tk.W, pady=(0, 10))
        
        self.test_question_text = scrolledtext.ScrolledText(test_frame, wrap=tk.WORD, height=8)
        self.test_question_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # ä¸‹åŠéƒ¨åˆ†ï¼šç”¨æˆ·ç­”æ¡ˆå’Œç»“æœ
        answer_frame = ttk.LabelFrame(paned_window, text="æ‚¨çš„ç­”æ¡ˆ", padding="10")
        paned_window.add(answer_frame, weight=1)
        
        answer_frame.columnconfigure(0, weight=1)
        answer_frame.rowconfigure(1, weight=1)
        
        ttk.Label(answer_frame, text="è¯·è¾“å…¥æ‚¨è¿˜åŸçš„å¥å­:").grid(row=0, column=0, sticky=tk.W, pady=(0, 10))
        
        self.user_answer_text = scrolledtext.ScrolledText(answer_frame, wrap=tk.WORD, height=6)
        self.user_answer_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # ç»“æœæ˜¾ç¤º
        self.restore_result_var = tk.StringVar()
        self.restore_result_var.set("è¯·ç”Ÿæˆæµ‹è¯•é¢˜ç›®å¹¶è¾“å…¥æ‚¨çš„ç­”æ¡ˆ")
        ttk.Label(answer_frame, textvariable=self.restore_result_var, justify=tk.LEFT).grid(row=2, column=0, sticky=tk.W, pady=(10, 0))
        
        # å½“å‰æµ‹è¯•æ•°æ®
        self.current_test_data = None
    
    def setup_relation_tab(self):
        """è®¾ç½®å­—ç¬¦è¯è¯­å…³ç³»åˆ†ææ ‡ç­¾é¡µ"""
        self.relation_tab.columnconfigure(0, weight=1)
        self.relation_tab.rowconfigure(1, weight=1)
        
        # æ§åˆ¶åŒºåŸŸ
        control_frame = ttk.Frame(self.relation_tab)
        control_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        ttk.Label(control_frame, text="èµ·å§‹åºå·:").grid(row=0, column=0, padx=(0, 5))
        self.relation_start_seq_var = tk.StringVar(value="1")
        ttk.Entry(control_frame, textvariable=self.relation_start_seq_var, width=10).grid(row=0, column=1, padx=(0, 15))
        
        ttk.Label(control_frame, text="ç»“æŸåºå·:").grid(row=0, column=2, padx=(0, 5))
        self.relation_end_seq_var = tk.StringVar(value="10")
        ttk.Entry(control_frame, textvariable=self.relation_end_seq_var, width=10).grid(row=0, column=3, padx=(0, 15))
        
        ttk.Button(control_frame, text="è®¡ç®—å…³ç³»", command=self.calculate_char_word_relation).grid(row=0, column=4, padx=(0, 10))
        ttk.Button(control_frame, text="ä¿å­˜ç»“æœ", command=self.save_relation_analysis).grid(row=0, column=5)
        
        # å…³ç³»åˆ†æè¡¨æ ¼
        self.relation_tab.columnconfigure(0, weight=1)
        self.relation_tab.rowconfigure(1, weight=1)
        
        table_frame = ttk.Frame(self.relation_tab)
        table_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        table_frame.columnconfigure(0, weight=1)
        table_frame.rowconfigure(0, weight=1)
        
        # æ»šåŠ¨æ¡
        scrollbar_y = ttk.Scrollbar(table_frame)
        scrollbar_y.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        scrollbar_x = ttk.Scrollbar(table_frame, orient=tk.HORIZONTAL)
        scrollbar_x.grid(row=1, column=0, sticky=(tk.W, tk.E))
        
        # Treeviewè¡¨æ ¼
        self.relation_tree = ttk.Treeview(table_frame, 
                                        columns=('åºå·', 'å¥å­', 'å­—ç¬¦ç»„åˆåˆ†æ', 'è¯è¯­æ•°å€¼åˆ†é…', 'å…³ç³»åˆ†æ'), 
                                        show='headings',
                                        yscrollcommand=scrollbar_y.set,
                                        xscrollcommand=scrollbar_x.set)
        
        # é…ç½®åˆ—
        columns_config = {
            'åºå·': 60, 'å¥å­': 150, 'å­—ç¬¦ç»„åˆåˆ†æ': 200, 'è¯è¯­æ•°å€¼åˆ†é…': 200, 'å…³ç³»åˆ†æ': 300
        }
        
        for col, width in columns_config.items():
            self.relation_tree.heading(col, text=col)
            self.relation_tree.column(col, width=width, anchor=tk.CENTER)
        
        self.relation_tree.column('å¥å­', anchor=tk.W)
        self.relation_tree.column('å­—ç¬¦ç»„åˆåˆ†æ', anchor=tk.W)
        self.relation_tree.column('è¯è¯­æ•°å€¼åˆ†é…', anchor=tk.W)
        self.relation_tree.column('å…³ç³»åˆ†æ', anchor=tk.W)
        
        self.relation_tree.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        scrollbar_y.config(command=self.relation_tree.yview)
        scrollbar_x.config(command=self.relation_tree.xview)
        
        # ç»¼åˆå…³ç³»åˆ†æåŒºåŸŸ
        summary_frame = ttk.LabelFrame(self.relation_tab, text="ç»¼åˆå…³ç³»åˆ†æ", padding="10")
        summary_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(10, 0))
        summary_frame.columnconfigure(0, weight=1)
        
        self.relation_summary_var = tk.StringVar()
        self.relation_summary_var.set("è¯·å…ˆè®¡ç®—å­—ç¬¦ä¸è¯è¯­æ•°å€¼åˆ†é…ä¹‹é—´çš„å…³ç³»")
        ttk.Label(summary_frame, textvariable=self.relation_summary_var, justify=tk.LEFT).grid(row=0, column=0, sticky=tk.W)
    
    def calculate_char_word_relation(self):
        """è®¡ç®—å­—ç¬¦ç»„åˆåˆ†æä¸è¯è¯­æ•°å€¼åˆ†é…ä¹‹é—´çš„å…³ç³»"""
        if not hasattr(self, 'analysis_data') or not self.analysis_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆå­—ç¬¦ç»„åˆåˆ†æ")
            return
        
        if not hasattr(self, 'words_value_data') or not self.words_value_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆè¯è¯­æ•°å€¼åˆ†é…")
            return
        
        try:
            start_seq = int(self.relation_start_seq_var.get())
            end_seq = int(self.relation_end_seq_var.get())
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œå…³ç³»åˆ†æ
        self.progress.start()
        thread = threading.Thread(target=self._calculate_char_word_relation_thread, args=(start_seq, end_seq))
        thread.daemon = True
        thread.start()

    def _calculate_char_word_relation_thread(self, start_seq, end_seq):
        """åœ¨åå°çº¿ç¨‹ä¸­è®¡ç®—å­—ç¬¦è¯è¯­å…³ç³»"""
        try:
            # è¿‡æ»¤æ•°æ®
            char_analysis_data = [d for d in self.analysis_data if start_seq <= d['åºå·'] <= end_seq]
            word_value_data = [d for d in self.words_value_data if start_seq <= d['åºå·'] <= end_seq]
            
            if not char_analysis_data or not word_value_data:
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¥å­"))
                return
            
            # æ„å»ºå…³ç³»åˆ†æç»“æœ
            relation_data = []
            
            for char_data, word_data in zip(char_analysis_data, word_value_data):
                if char_data['åºå·'] != word_data['åºå·']:
                    continue
                
                # è§£æå­—ç¬¦ç»„åˆåˆ†æ
                char_combination = char_data['å­—ç¬¦ç»„åˆ']
                char_values_str = char_data['æ•°å€¼']
                
                # è§£æå­—ç¬¦å’Œæ•°å€¼
                chars = re.findall(r"'([^']*)'", char_combination)
                char_values = [int(x.strip()) for x in char_values_str.split('+')]
                
                # è§£æè¯è¯­æ•°å€¼åˆ†é…
                word_combination = word_data['è¯è¯­ç»„åˆ']
                word_values_str = word_data['æ•°å€¼']
                
                # è§£æè¯è¯­å’Œæ•°å€¼
                words = re.findall(r"'([^']*)'", word_combination)
                word_values = [int(x.strip()) for x in word_values_str.split('+')]
                
                # è®¡ç®—å­—ç¬¦ä¸è¯è¯­ä¹‹é—´çš„æ˜ å°„å…³ç³»
                relation_text = self._build_char_word_mapping(chars, char_values, words, word_values)
                
                relation_data.append({
                    'åºå·': char_data['åºå·'],
                    'å¥å­': char_data['å¥å­'],
                    'å­—ç¬¦ç»„åˆåˆ†æ': char_values_str,
                    'è¯è¯­æ•°å€¼åˆ†é…': word_values_str,
                    'å…³ç³»åˆ†æ': relation_text
                })
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_relation_results, relation_data)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è®¡ç®—å…³ç³»æ—¶å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)

    def _build_char_word_mapping(self, chars, char_values, words, word_values):
        """æ„å»ºå­—ç¬¦ä¸è¯è¯­çš„æ˜ å°„å…³ç³»"""
        try:
            if not chars or not words:
                return "æ— æ³•å»ºç«‹æ˜ å°„å…³ç³»"
            
            # åˆ†æå­—ç¬¦å¦‚ä½•ç»„åˆæˆè¯è¯­
            mapping_relations = []
            char_index = 0
            
            for word, word_value in zip(words, word_values):
                word_length = len(word)
                
                # è·å–è¯è¯­å¯¹åº”çš„å­—ç¬¦
                word_chars = chars[char_index:char_index + word_length]
                word_char_values = char_values[char_index:char_index + word_length]
                
                # æ„å»ºæ˜ å°„å…³ç³»å­—ç¬¦ä¸²
                if len(word_chars) == 1:
                    # å•ä¸ªå­—ç¬¦å¯¹åº”å•ä¸ªè¯è¯­
                    mapping_relations.append(f"{word_char_values[0]}={word_value}={word_chars[0]}")
                else:
                    # å¤šä¸ªå­—ç¬¦å¯¹åº”ä¸€ä¸ªè¯è¯­
                    char_values_str = '+'.join(map(str, word_char_values))
                    mapping_relations.append(f"{char_values_str}={word_value}={word}")
                
                char_index += word_length
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‰©ä½™çš„å­—ç¬¦
            if char_index < len(chars):
                remaining_chars = chars[char_index:]
                remaining_values = char_values[char_index:]
                if remaining_chars:
                    char_values_str = '+'.join(map(str, remaining_values))
                    mapping_relations.append(f"{char_values_str}=?={'+'.join(remaining_chars)}")
            
            return ", ".join(mapping_relations)
            
        except Exception as e:
            return f"æ„å»ºæ˜ å°„å…³ç³»æ—¶å‡ºé”™: {str(e)}"

    def _update_relation_results(self, relation_data):
        """æ›´æ–°å…³ç³»åˆ†æç»“æœ"""
        self.relation_data = relation_data
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.relation_tree.get_children():
            self.relation_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for data in relation_data:
            self.relation_tree.insert('', 'end', values=(
                data['åºå·'],
                data['å¥å­'],
                data['å­—ç¬¦ç»„åˆåˆ†æ'],
                data['è¯è¯­æ•°å€¼åˆ†é…'],
                data['å…³ç³»åˆ†æ']
            ))
        
        # æ›´æ–°ç»¼åˆå…³ç³»åˆ†æ
        summary = self._generate_advanced_relation_summary(relation_data)
        self.relation_summary_var.set(summary)
        
        messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸåˆ†æ {len(relation_data)} ä¸ªå¥å­çš„å­—ç¬¦è¯è¯­å…³ç³»ï¼")

    def _generate_advanced_relation_summary(self, relation_data):
        """ç”Ÿæˆé«˜çº§å…³ç³»åˆ†ææ‘˜è¦"""
        try:
            if not relation_data:
                return "æ²¡æœ‰å¯ç”¨çš„å…³ç³»åˆ†ææ•°æ®"
            
            # æ”¶é›†æ‰€æœ‰æ˜ å°„å…³ç³»
            all_mappings = {}
            char_word_mapping = {}  # å­—ç¬¦ç»„åˆ -> è¯è¯­
            word_char_mapping = {}  # è¯è¯­ -> å­—ç¬¦ç»„åˆ
            
            for data in relation_data:
                relation_text = data['å…³ç³»åˆ†æ']
                mappings = relation_text.split(', ')
                
                for mapping in mappings:
                    if '=' in mapping:
                        parts = mapping.split('=')
                        if len(parts) >= 3:
                            char_part = parts[0]  # å­—ç¬¦æ•°å€¼éƒ¨åˆ†
                            word_value = parts[1]  # è¯è¯­æ•°å€¼
                            word_part = parts[2]   # è¯è¯­éƒ¨åˆ†
                            
                            # è®°å½•æ˜ å°„å…³ç³»
                            key = f"{char_part}â†’{word_value}"
                            if key not in all_mappings:
                                all_mappings[key] = []
                            all_mappings[key].append(word_part)
                            
                            # è®°å½•åŒå‘æ˜ å°„
                            char_word_mapping[char_part] = word_part
                            word_char_mapping[word_part] = char_part
            
            # ä¿å­˜ç¨³å®šçš„æ˜ å°„å…³ç³»
            self.stable_mappings = {}
            for key, words in all_mappings.items():
                if len(set(words)) == 1:  # æ‰€æœ‰æ˜ å°„éƒ½æŒ‡å‘åŒä¸€ä¸ªè¯è¯­
                    char_part = key.split('â†’')[0]
                    self.stable_mappings[char_part] = words[0]
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"é«˜çº§å…³ç³»åˆ†ææ‘˜è¦ ({len(relation_data)} ä¸ªå¥å­)\n\n"
            summary += "å‘ç°çš„æ˜ å°„æ¨¡å¼:\n"
            
            # ç»Ÿè®¡æœ€å¸¸è§çš„æ˜ å°„
            common_mappings = []
            for key, words in all_mappings.items():
                if len(set(words)) == 1:  # æ‰€æœ‰æ˜ å°„éƒ½æŒ‡å‘åŒä¸€ä¸ªè¯è¯­
                    common_mappings.append((key, words[0], len(words)))
            
            # æŒ‰é¢‘ç‡æ’åº
            common_mappings.sort(key=lambda x: x[2], reverse=True)
            
            for i, (key, word, count) in enumerate(common_mappings[:10]):  # æ˜¾ç¤ºå‰10ä¸ª
                summary += f"{i+1}. {key} â†’ '{word}' (å‡ºç°{count}æ¬¡)\n"
            
            summary += f"\næ€»æ˜ å°„æ¨¡å¼æ•°: {len(all_mappings)}"
            summary += f"\nç¨³å®šæ˜ å°„æ•°: {len(common_mappings)}"
            
            # æ·»åŠ ä½¿ç”¨å»ºè®®
            summary += "\n\nä½¿ç”¨å»ºè®®:"
            summary += "\n1. ä½¿ç”¨ç¨³å®šæ˜ å°„æ¨¡å¼æ¥åˆ†è¯æ–°å¥å­"
            summary += "\n2. å¯¹äºæœªçŸ¥å­—ç¬¦ç»„åˆï¼ŒæŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ˜ å°„æ¨¡å¼"
            summary += "\n3. ç»“åˆå­—ç¬¦æ€ç»´ç½‘ç»œè¿›è¡ŒéªŒè¯"
            
            return summary
            
        except Exception as e:
            return f"ç”Ÿæˆé«˜çº§å…³ç³»åˆ†ææ—¶å‡ºé”™: {str(e)}"

    def save_relation_analysis(self):
        """ä¿å­˜å…³ç³»åˆ†æç»“æœ"""
        if not hasattr(self, 'relation_data') or not self.relation_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å…³ç³»åˆ†ææ•°æ®")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜å…³ç³»åˆ†æç»“æœ",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                # è·å–å½“å‰è¡¨æ ¼ä¸­çš„æ‰€æœ‰æ•°æ®
                data = []
                for item in self.relation_tree.get_children():
                    values = self.relation_tree.item(item, 'values')
                    data.append({
                        'åºå·': values[0],
                        'å¥å­': values[1],
                        'å­—ç¬¦ç»„åˆåˆ†æ': values[2],
                        'è¯è¯­æ•°å€¼åˆ†é…': values[3],
                        'å…³ç³»åˆ†æ': values[4]
                    })
                
                df = pd.DataFrame(data)
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                messagebox.showinfo("æˆåŠŸ", f"å…³ç³»åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    # æ·»åŠ æ–°æ–¹æ³•ï¼šåŸºäºæ˜ å°„å…³ç³»åˆ†è¯
    def tokenize_using_mappings(self, sentence, char_values):
        """ä½¿ç”¨å·²æœ‰çš„æ˜ å°„å…³ç³»å¯¹å¥å­è¿›è¡Œåˆ†è¯"""
        try:
            if not hasattr(self, 'stable_mappings') or not self.stable_mappings:
                return self.tokenize_sentence(sentence)  # å›é€€åˆ°åŸºæœ¬åˆ†è¯
            
            # å°†å­—ç¬¦æ•°å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ä»¥ä¾¿åŒ¹é…
            char_values_str = '+'.join(map(str, char_values))
            
            # å°è¯•ä½¿ç”¨æ˜ å°„å…³ç³»è¿›è¡Œåˆ†è¯
            words = []
            current_pos = 0
            chars = list(sentence)
            
            while current_pos < len(chars):
                # å°è¯•æ‰¾åˆ°æœ€é•¿çš„åŒ¹é…
                best_match = None
                best_match_length = 0
                
                for i in range(current_pos + 1, len(chars) + 1):
                    current_chars = chars[current_pos:i]
                    current_values = char_values[current_pos:i]
                    current_key = '+'.join(map(str, current_values))
                    
                    if current_key in self.stable_mappings:
                        if len(current_chars) > best_match_length:
                            best_match = self.stable_mappings[current_key]
                            best_match_length = len(current_chars)
                
                if best_match:
                    words.append(best_match)
                    current_pos += best_match_length
                else:
                    # æ²¡æœ‰æ‰¾åˆ°æ˜ å°„ï¼Œä½¿ç”¨å•ä¸ªå­—ç¬¦
                    words.append(chars[current_pos])
                    current_pos += 1
            
            return words
            
        except Exception as e:
            print(f"ä½¿ç”¨æ˜ å°„åˆ†è¯æ—¶å‡ºé”™: {e}")
            return self.tokenize_sentence(sentence)  # å‡ºé”™æ—¶å›é€€åˆ°åŸºæœ¬åˆ†è¯

    def generate_restore_test(self):
        """ç”Ÿæˆå¥å­è¿˜åŸæµ‹è¯•"""
        if not self.char_mapping:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨å’Œæ€ç»´ç½‘ç»œ")
            return
        
        test_mode = self.test_mode_var.get()
        
        if test_mode == "specific":
            try:
                seq = int(self.restore_seq_var.get())
                # æŸ¥æ‰¾æŒ‡å®šå¥å­
                target_sentence = None
                for s in self.sentences:
                    if s[0] == seq:
                        target_sentence = s
                        break
                
                if not target_sentence:
                    messagebox.showerror("é”™è¯¯", f"æœªæ‰¾åˆ°åºå·ä¸º {seq} çš„å¥å­")
                    return
                
                self._create_restore_test(target_sentence)
                
            except ValueError:
                messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„å¥å­åºå·")
                return
        else:
            # éšæœºé€‰æ‹©å¥å­
            if not self.sentences:
                messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
                return
            
            random_sentence = random.choice(self.sentences)
            self._create_restore_test(random_sentence)
    
    def _create_restore_test(self, sentence):
        """åˆ›å»ºè¿˜åŸæµ‹è¯•é¢˜ç›®"""
        seq, text = sentence
        
        # ç”Ÿæˆå­—ç¬¦æ•°å€¼åˆ†é…
        char_values = self.assign_values(text)
        
        # åˆ›å»ºæµ‹è¯•é¢˜ç›® - æŒ–ç©ºéƒ¨åˆ†å­—ç¬¦
        test_chars = []
        answer_positions = []
        
        # éšæœºé€‰æ‹©è¦æŒ–ç©ºçš„å­—ç¬¦ä½ç½®ï¼ˆè‡³å°‘ä¿ç•™30%çš„å­—ç¬¦ï¼‰
        n = len(text)
        num_blanks = max(1, n // 3)  # æŒ–ç©ºçº¦1/3çš„å­—ç¬¦
        blank_positions = random.sample(range(n), num_blanks)
        
        for i, (char, value) in enumerate(char_values):
            if i in blank_positions:
                test_chars.append(f"[?({value})]")
                answer_positions.append((i, char, value))
            else:
                test_chars.append(f"{char}({value})")
        
        test_question = " ".join(test_chars)
        
        # æ„å»ºæµ‹è¯•è¯´æ˜
        instructions = f"æµ‹è¯•å¥å­ #{seq}\n\n"
        instructions += "é¢˜ç›®è¯´æ˜ï¼š\n"
        instructions += "- æ–¹æ‹¬å· [?(æ•°å€¼)] è¡¨ç¤ºéœ€è¦è¿˜åŸçš„å­—ç¬¦\n"
        instructions += "- å…¶ä»–å­—ç¬¦åçš„(æ•°å€¼)è¡¨ç¤ºè¯¥å­—ç¬¦çš„æ˜ å°„æ•°å€¼\n"
        instructions += "- è¯·æ ¹æ®å­—ç¬¦æ˜ å°„è¡¨å’Œæ€ç»´ç½‘ç»œå…³ç³»è¿˜åŸå®Œæ•´çš„å¥å­\n\n"
        instructions += "æµ‹è¯•é¢˜ç›®ï¼š\n"
        instructions += test_question
        
        # æ˜¾ç¤ºæµ‹è¯•é¢˜ç›®
        self.test_question_text.delete(1.0, tk.END)
        self.test_question_text.insert(1.0, instructions)
        
        # æ¸…ç©ºç”¨æˆ·ç­”æ¡ˆå’Œç»“æœ
        self.user_answer_text.delete(1.0, tk.END)
        self.restore_result_var.set("è¯·åœ¨ä¸Šæ–¹è¾“å…¥æ‚¨çš„ç­”æ¡ˆ")
        
        # ä¿å­˜å½“å‰æµ‹è¯•æ•°æ®
        self.current_test_data = {
            'original_sentence': text,
            'seq': seq,
            'char_values': char_values,
            'answer_positions': answer_positions,
            'test_question': test_question
        }
        
        messagebox.showinfo("æˆåŠŸ", f"å·²ç”Ÿæˆå¥å­ #{seq} çš„è¿˜åŸæµ‹è¯•")
    
    def check_restore_answer(self):
        """æ£€æŸ¥ç”¨æˆ·ç­”æ¡ˆ"""
        if not self.current_test_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆæµ‹è¯•é¢˜ç›®")
            return
        
        user_answer = self.user_answer_text.get(1.0, tk.END).strip()
        if not user_answer:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥æ‚¨çš„ç­”æ¡ˆ")
            return
        
        original_sentence = self.current_test_data['original_sentence']
        seq = self.current_test_data['seq']
        
        # ç®€å•çš„ç­”æ¡ˆæ£€æŸ¥
        if user_answer == original_sentence:
            result = f"âœ… æ­å–œï¼ç­”æ¡ˆå®Œå…¨æ­£ç¡®ï¼\nå¥å­ #{seq}: {original_sentence}"
            self.restore_result_var.set(result)
            messagebox.showinfo("ç»“æœ", "ç­”æ¡ˆæ­£ç¡®ï¼")
        else:
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = self._calculate_similarity(user_answer, original_sentence)
            
            result = f"âŒ ç­”æ¡ˆä¸å®Œå…¨æ­£ç¡®\n"
            result += f"æ‚¨çš„ç­”æ¡ˆ: {user_answer}\n"
            result += f"æ­£ç¡®ç­”æ¡ˆ: {original_sentence}\n"
            result += f"ç›¸ä¼¼åº¦: {similarity:.1%}"
            
            self.restore_result_var.set(result)
            
            # æä¾›æ›´è¯¦ç»†çš„åé¦ˆ
            self._provide_detailed_feedback(user_answer, original_sentence)
    
    def _calculate_similarity(self, answer, original):
        """è®¡ç®—ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„å­—ç¬¦çº§åˆ«ç›¸ä¼¼åº¦è®¡ç®—
        if len(answer) == 0 or len(original) == 0:
            return 0.0
        
        # ä½¿ç”¨é›†åˆè®¡ç®—Jaccardç›¸ä¼¼åº¦
        set_answer = set(answer)
        set_original = set(original)
        
        intersection = len(set_answer & set_original)
        union = len(set_answer | set_original)
        
        jaccard_sim = intersection / union if union > 0 else 0
        
        # ä½¿ç”¨åºåˆ—ç›¸ä¼¼åº¦
        min_len = min(len(answer), len(original))
        if min_len == 0:
            sequence_sim = 0
        else:
            match_count = sum(1 for i in range(min_len) if answer[i] == original[i])
            sequence_sim = match_count / len(original)
        
        # ç»¼åˆç›¸ä¼¼åº¦
        overall_sim = (jaccard_sim + sequence_sim) / 2
        return overall_sim
    
    def _provide_detailed_feedback(self, user_answer, original_sentence):
        """æä¾›è¯¦ç»†çš„åé¦ˆä¿¡æ¯"""
        feedback = "è¯¦ç»†åé¦ˆï¼š\n"
        
        # é•¿åº¦æ¯”è¾ƒ
        if len(user_answer) != len(original_sentence):
            feedback += f"- é•¿åº¦ä¸åŒ¹é…ï¼šæ‚¨çš„ç­”æ¡ˆæœ‰ {len(user_answer)} ä¸ªå­—ç¬¦ï¼Œæ­£ç¡®ç­”æ¡ˆæœ‰ {len(original_sentence)} ä¸ªå­—ç¬¦\n"
        
        # å­—ç¬¦æ¯”è¾ƒ
        min_len = min(len(user_answer), len(original_sentence))
        wrong_positions = []
        
        for i in range(min_len):
            if user_answer[i] != original_sentence[i]:
                wrong_positions.append((i, user_answer[i], original_sentence[i]))
        
        if wrong_positions:
            feedback += f"- æœ‰ {len(wrong_positions)} ä¸ªä½ç½®å­—ç¬¦ä¸æ­£ç¡®ï¼š\n"
            for pos, user_char, correct_char in wrong_positions[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                feedback += f"  ä½ç½® {pos+1}: æ‚¨è¾“å…¥ '{user_char}'ï¼Œåº”ä¸º '{correct_char}'\n"
            if len(wrong_positions) > 5:
                feedback += f"  è¿˜æœ‰ {len(wrong_positions) - 5} ä¸ªé”™è¯¯...\n"
        
        # å»ºè®®
        feedback += "\nå»ºè®®ï¼š\n"
        feedback += "- æŸ¥çœ‹å­—ç¬¦æ˜ å°„è¡¨ç¡®è®¤æ•°å€¼å¯¹åº”çš„å­—ç¬¦\n"
        feedback += "- æ£€æŸ¥æ€ç»´ç½‘ç»œä¸­å­—ç¬¦çš„è¿æ¥å…³ç³»\n"
        feedback += "- æ³¨æ„å¥å­çš„è¯­æ³•å’Œè¯­ä¹‰åˆç†æ€§\n"
        
        # æ˜¾ç¤ºåœ¨ç»“æœä¸­
        current_result = self.restore_result_var.get()
        self.restore_result_var.set(current_result + "\n\n" + feedback)
    
    def show_restore_answer(self):
        """æ˜¾ç¤ºæ­£ç¡®ç­”æ¡ˆ"""
        if not self.current_test_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆæµ‹è¯•é¢˜ç›®")
            return
        
        original_sentence = self.current_test_data['original_sentence']
        seq = self.current_test_data['seq']
        char_values = self.current_test_data['char_values']
        
        # æ˜¾ç¤ºå®Œæ•´ç­”æ¡ˆ
        answer_info = f"æ­£ç¡®ç­”æ¡ˆï¼ˆå¥å­ #{seq}ï¼‰:\n"
        answer_info += f"å®Œæ•´å¥å­: {original_sentence}\n\n"
        answer_info += "å­—ç¬¦æ•°å€¼æ˜ å°„:\n"
        
        for char, value in char_values:
            answer_info += f"  '{char}' â†’ {value}\n"
        
        answer_info += f"\nå¥å­é•¿åº¦: {len(original_sentence)} å­—ç¬¦"
        answer_info += f"\næ•°å€¼æ€»å’Œ: {sum(val for _, val in char_values)}"
        
        # åœ¨ç”¨æˆ·ç­”æ¡ˆåŒºåŸŸæ˜¾ç¤ºæ­£ç¡®ç­”æ¡ˆ
        self.user_answer_text.delete(1.0, tk.END)
        self.user_answer_text.insert(1.0, original_sentence)
        
        self.restore_result_var.set(answer_info)
        messagebox.showinfo("æ­£ç¡®ç­”æ¡ˆ", f"å¥å­ #{seq}: {original_sentence}")

    def generate_mind_network(self):
        """ç”Ÿæˆå­—ç¬¦æ€ç»´ç½‘ç»œ"""
        if not self.char_mapping:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        self.progress.start()
        self.flow_status_var.set("æ­£åœ¨ç”Ÿæˆæ€ç»´ç½‘ç»œ...")
        thread = threading.Thread(target=self._generate_mind_network_thread)
        thread.daemon = True
        thread.start()
    
    def _generate_mind_network_thread(self):
        """åœ¨åå°çº¿ç¨‹ä¸­ç”Ÿæˆæ€ç»´ç½‘ç»œ"""
        try:
            # æ„å»ºæ€ç»´ç½‘ç»œæ•°æ®
            network_data = self._build_mind_network_data()
            
            # åˆ›å»ºäº¤äº’å¼ç½‘ç»œå›¾
            self._create_interactive_network(network_data)
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°çŠ¶æ€
            self.root.after(0, lambda: self.flow_status_var.set("æ€ç»´ç½‘ç»œç”Ÿæˆå®Œæˆï¼è¯·ç‚¹å‡»'åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€'æŸ¥çœ‹"))
            
        except Exception as e:
            error_msg = f"ç”Ÿæˆæ€ç»´ç½‘ç»œæ—¶å‡ºé”™: {str(e)}\n\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{self._format_exception(e)}"
            self.root.after(0, lambda: self._show_error_dialog(error_msg))
            self.root.after(0, lambda: self.flow_status_var.set("ç”Ÿæˆå¤±è´¥"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _format_exception(self, e):
        """æ ¼å¼åŒ–å¼‚å¸¸ä¿¡æ¯"""
        import traceback
        tb_str = traceback.format_exc()
        return f"å¼‚å¸¸ç±»å‹: {type(e).__name__}\nå¼‚å¸¸ä¿¡æ¯: {str(e)}\n\nå †æ ˆè·Ÿè¸ª:\n{tb_str}"
    
    def _show_error_dialog(self, error_msg):
        """æ˜¾ç¤ºå¯å¤åˆ¶é”™è¯¯ä¿¡æ¯çš„å¯¹è¯æ¡†"""
        error_dialog = tk.Toplevel(self.root)
        error_dialog.title("æ€ç»´ç½‘ç»œç”Ÿæˆé”™è¯¯")
        error_dialog.geometry("600x400")
        error_dialog.transient(self.root)
        error_dialog.grab_set()
        
        # è®¾ç½®å¯¹è¯æ¡†ä½ç½®åœ¨çˆ¶çª—å£ä¸­å¿ƒ
        error_dialog.update_idletasks()
        x = self.root.winfo_x() + (self.root.winfo_width() - error_dialog.winfo_width()) // 2
        y = self.root.winfo_y() + (self.root.winfo_height() - error_dialog.winfo_height()) // 2
        error_dialog.geometry(f"+{x}+{y}")
        
        # åˆ›å»ºæ¡†æ¶
        main_frame = ttk.Frame(error_dialog, padding="10")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        error_dialog.columnconfigure(0, weight=1)
        error_dialog.rowconfigure(0, weight=1)
        main_frame.columnconfigure(0, weight=1)
        main_frame.rowconfigure(1, weight=1)
        
        # é”™è¯¯æ ‡é¢˜
        title_label = ttk.Label(main_frame, text="æ€ç»´ç½‘ç»œç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯", 
                               font=("Arial", 12, "bold"), foreground="red")
        title_label.grid(row=0, column=0, sticky=tk.W, pady=(0, 10))
        
        # é”™è¯¯ä¿¡æ¯æ–‡æœ¬æ¡†
        error_text = scrolledtext.ScrolledText(main_frame, wrap=tk.WORD, width=70, height=15)
        error_text.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        error_text.insert(tk.END, error_msg)
        error_text.config(state=tk.DISABLED)  # è®¾ç½®ä¸ºåªè¯»
        
        # æŒ‰é’®æ¡†æ¶
        button_frame = ttk.Frame(main_frame)
        button_frame.grid(row=2, column=0, sticky=tk.E)
        
        # å¤åˆ¶æŒ‰é’®
        copy_button = ttk.Button(button_frame, text="å¤åˆ¶é”™è¯¯ä¿¡æ¯", 
                                command=lambda: self._copy_to_clipboard(error_msg))
        copy_button.grid(row=0, column=0, padx=(0, 10))
        
        # å…³é—­æŒ‰é’®
        close_button = ttk.Button(button_frame, text="å…³é—­", 
                                 command=error_dialog.destroy)
        close_button.grid(row=0, column=1)
    
    def _copy_to_clipboard(self, text):
        """å¤åˆ¶æ–‡æœ¬åˆ°å‰ªè´´æ¿"""
        self.root.clipboard_clear()
        self.root.clipboard_append(text)
        messagebox.showinfo("æˆåŠŸ", "é”™è¯¯ä¿¡æ¯å·²å¤åˆ¶åˆ°å‰ªè´´æ¿")
    
    def _build_mind_network_data(self):
        """æ„å»ºæ€ç»´ç½‘ç»œæ•°æ® - åŸºäºå­—ç¬¦åœ¨å¥å­ä¸­çš„é¡ºåºè¿æ¥"""
        network_data = {
            'nodes': {},  # èŠ‚ç‚¹: {ä½ç½®: (x, y), å­—ç¬¦: char, æ•°å€¼åˆ—è¡¨: values, å‡ºç°æ¬¡æ•°: count}
            'edges': [],  # è¾¹: (èµ·ç‚¹, ç»ˆç‚¹, æƒé‡, å¥å­æ¥æº)
        }
        
        # ä¸ºæ¯ä¸ªå­—ç¬¦åˆ›å»ºèŠ‚ç‚¹
        chars = list(self.char_mapping.keys())
        
        if not chars:
            return network_data
            
        # è®¡ç®—æ¯ä¸ªå­—ç¬¦çš„å‡ºç°æ¬¡æ•°
        char_counts = {}
        for char, values in self.char_mapping.items():
            char_counts[char] = len(values)
        
        # ä¸ºèŠ‚ç‚¹åˆ†é…ä½ç½®ï¼ˆä½¿ç”¨åŠ›å¯¼å‘å¸ƒå±€çš„åˆå§‹ä½ç½®ï¼‰
        # ä½¿ç”¨åœ†å½¢å¸ƒå±€é¿å…é‡å 
        radius = 10
        angle_step = 2 * np.pi / len(chars)
        
        for i, char in enumerate(chars):
            # åœ¨åœ†å½¢ä¸Šåˆ†å¸ƒèŠ‚ç‚¹
            angle = i * angle_step
            x = radius * np.cos(angle)
            y = radius * np.sin(angle)
            
            network_data['nodes'][char] = {
                'pos': (x, y),
                'char': char,
                'values': self.char_mapping[char],
                'count': char_counts[char]
            }
        
        # åŸºäºå­—ç¬¦åœ¨å¥å­ä¸­çš„é¡ºåºå»ºç«‹è¿æ¥å…³ç³»
        if hasattr(self, 'analysis_data') and self.analysis_data:
            for analysis in self.analysis_data:
                sentence = analysis['å¥å­']
                seq = analysis['åºå·']
                
                # è§£æå­—ç¬¦ç»„åˆå’Œæ•°å€¼
                char_combination = analysis['å­—ç¬¦ç»„åˆ']
                values_str = analysis['æ•°å€¼']
                
                # è§£æå­—ç¬¦å’Œæ•°å€¼
                try:
                    chars_in_sentence = re.findall(r"'([^']*)'", char_combination)
                    values = [int(x.strip()) for x in values_str.split('+')]
                    
                    # ç¡®ä¿å­—ç¬¦å’Œæ•°å€¼æ•°é‡åŒ¹é…
                    if len(chars_in_sentence) != len(values):
                        continue
                        
                    # ä¸ºå¥å­ä¸­çš„å­—ç¬¦å»ºç«‹é¡ºåºè¿æ¥
                    for i in range(len(chars_in_sentence) - 1):
                        char1 = chars_in_sentence[i]
                        char2 = chars_in_sentence[i + 1]
                        value1 = values[i]
                        value2 = values[i + 1]
                        
                        # ç¡®ä¿å­—ç¬¦åœ¨èŠ‚ç‚¹ä¸­
                        if char1 not in network_data['nodes'] or char2 not in network_data['nodes']:
                            continue
                            
                        # è®¡ç®—è¿æ¥æƒé‡ï¼ˆåŸºäºå­—ç¬¦åœ¨å¥å­ä¸­çš„ä½ç½®å…³ç³»ï¼Œè€Œä¸æ˜¯é¢‘ç‡ï¼‰
                        # ä½¿ç”¨ç®€å•çš„å›ºå®šæƒé‡ï¼Œå› ä¸ºé‡ç‚¹æ˜¯æ˜¾ç¤ºè¿æ¥å…³ç³»
                        weight = 1.0
                        
                        # æ·»åŠ è¾¹
                        network_data['edges'].append({
                            'from': char1,
                            'to': char2,
                            'weight': weight,
                            'sentence': seq,
                            'sentence_text': sentence,
                            'from_value': value1,
                            'to_value': value2
                        })
                except Exception as e:
                    print(f"è§£æå¥å­æ—¶å‡ºé”™: {e}")
                    continue
        
        return network_data
    
    def _create_interactive_network(self, network_data):
        """åˆ›å»ºäº¤äº’å¼ç½‘ç»œå›¾"""
        if not network_data['nodes']:
            return
        
        # åˆ›å»ºèŠ‚ç‚¹å’Œè¾¹çš„æ•°æ®
        node_x = []
        node_y = []
        node_text = []
        node_size = []
        node_color = []
        
        # è®¡ç®—èŠ‚ç‚¹å¤§å°å’Œé¢œè‰²
        counts = [node['count'] for node in network_data['nodes'].values()]
        max_count = max(counts) if counts else 1
        
        for char, node_info in network_data['nodes'].items():
            x, y = node_info['pos']
            count = node_info['count']
            values = node_info['values']
            
            node_x.append(x)
            node_y.append(y)
            
            # èŠ‚ç‚¹æ–‡æœ¬
            value_str = '/'.join(map(str, sorted(values)))
            text = f"å­—ç¬¦: {char}<br>å‡ºç°æ¬¡æ•°: {count}<br>æ•°å€¼åˆ—è¡¨: {value_str}"
            node_text.append(text)
            
            # èŠ‚ç‚¹å¤§å°åŸºäºå‡ºç°æ¬¡æ•°
            size = 15 + (count / max_count) * 25
            node_size.append(size)
            
            # èŠ‚ç‚¹é¢œè‰²åŸºäºæ•°å€¼çš„å¤šæ ·æ€§
            value_diversity = len(set(values)) / len(values) if values else 0
            node_color.append(value_diversity)
        
        # åˆ›å»ºèŠ‚ç‚¹trace
        node_trace = go.Scatter(
            x=node_x, y=node_y,
            mode='markers+text',
            hoverinfo='text',
            text=[node['char'] for node in network_data['nodes'].values()],
            textposition="middle center",
            marker=dict(
                size=node_size,
                color=node_color,
                colorscale='Viridis',
                showscale=True,
                colorbar=dict(
                    title=dict(
                        text='æ•°å€¼å¤šæ ·æ€§',
                        side='right'
                    ),
                    thickness=15
                ),
                line=dict(width=2, color='darkblue')
            ),
            hovertext=node_text
        )
        
        # åˆ›å»ºè¾¹trace
        edge_traces = []
        
        # é™åˆ¶è¾¹æ•°é‡ï¼Œé¿å…è¿‡äºæ··ä¹±
        edges_to_show = network_data['edges'][:min(200, len(network_data['edges']))]
        
        for edge in edges_to_show:
            from_char = edge['from']
            to_char = edge['to']
            
            if from_char in network_data['nodes'] and to_char in network_data['nodes']:
                from_pos = network_data['nodes'][from_char]['pos']
                to_pos = network_data['nodes'][to_char]['pos']
                
                # è¾¹çš„é¢œè‰²å’Œæ ·å¼
                color = 'rgba(128, 128, 128, 0.5)'
                linewidth = 1
                
                # åˆ›å»ºè¾¹trace
                edge_trace = go.Scatter(
                    x=[from_pos[0], to_pos[0], None],
                    y=[from_pos[1], to_pos[1], None],
                    mode='lines',
                    line=dict(width=linewidth, color=color),
                    hoverinfo='text',
                    text=f"ä»: {from_char}({edge['from_value']}) â†’ åˆ°: {to_char}({edge['to_value']})<br>å¥å­ {edge['sentence']}: {edge['sentence_text']}",
                    showlegend=False
                )
                edge_traces.append(edge_trace)
        
        # åˆ›å»ºå›¾å½¢
        fig = go.Figure(data=edge_traces + [node_trace])
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=dict(
                text='å­—ç¬¦æ€ç»´ç½‘ç»œ - åŸºäºå¥å­é¡ºåºè¿æ¥',
                font=dict(size=16)
            ),
            showlegend=False,
            hovermode='closest',
            margin=dict(b=20, l=5, r=5, t=40),
            annotations=[dict(
                text="èŠ‚ç‚¹å¤§å°è¡¨ç¤ºå­—ç¬¦å‡ºç°é¢‘ç‡ï¼Œé¢œè‰²è¡¨ç¤ºæ•°å€¼å¤šæ ·æ€§ï¼Œè¿çº¿è¡¨ç¤ºå­—ç¬¦åœ¨å¥å­ä¸­çš„é¡ºåºå…³ç³»",
                showarrow=False,
                xref="paper", yref="paper",
                x=0.005, y=-0.002,
                xanchor="left", yanchor="bottom",
                font=dict(size=10)
            )],
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            # è®¾ç½®å›¾å½¢å°ºå¯¸
            width=1000,
            height=800,
            # æ·»åŠ ç¼©æ”¾å’Œå¹³ç§»åŠŸèƒ½
            dragmode='pan'
        )
        
        # ä¿å­˜ä¸ºHTMLæ–‡ä»¶
        self.network_html_path = tempfile.NamedTemporaryFile(
            suffix='.html', delete=False, prefix='mind_network_'
        ).name
        
        pyo.plot(fig, filename=self.network_html_path, auto_open=False)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯åˆ°æ–‡ä»¶
        with open(self.network_html_path, 'r', encoding='utf-8') as file:
            content = file.read()
        
        # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_html = f"""
        <div style="position: absolute; top: 10px; right: 10px; background: white; padding: 10px; border-radius: 5px; border: 1px solid #ccc;">
            <h4>ç½‘ç»œç»Ÿè®¡</h4>
            <p>æ€»å­—ç¬¦æ•°: {len(network_data['nodes'])}</p>
            <p>æ€»è¿æ¥æ•°: {len(network_data['edges'])}</p>
            <p>æ˜¾ç¤ºè¿æ¥æ•°: {len(edges_to_show)}</p>
        </div>
        """
        
        # å°†ç»Ÿè®¡ä¿¡æ¯æ’å…¥åˆ°bodyæ ‡ç­¾å†…
        content = content.replace('</body>', stats_html + '</body>')
        
        with open(self.network_html_path, 'w', encoding='utf-8') as file:
            file.write(content)
    
    def open_network_in_browser(self):
        """åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ç½‘ç»œå›¾"""
        if hasattr(self, 'network_html_path') and os.path.exists(self.network_html_path):
            webbrowser.open('file://' + os.path.abspath(self.network_html_path))
        else:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆæ€ç»´ç½‘ç»œ")
    
    def save_flow_chart(self):
        """ä¿å­˜å½“å‰æ€ç»´ç½‘ç»œå›¾"""
        if not hasattr(self, 'network_html_path') or not os.path.exists(self.network_html_path):
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„æ€ç»´ç½‘ç»œå›¾")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜æ€ç»´ç½‘ç»œå›¾",
            defaultextension=".html",
            filetypes=[("HTML files", "*.html"), ("PNG files", "*.png"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                import shutil
                shutil.copy2(self.network_html_path, filename)
                messagebox.showinfo("æˆåŠŸ", f"æ€ç»´ç½‘ç»œå›¾å·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ€ç»´ç½‘ç»œå›¾æ—¶å‡ºé”™: {e}")

    def generate_char_mapping(self):
        """ç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨"""
        if not hasattr(self, 'analysis_data') or not self.analysis_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆç”Ÿæˆå­—ç¬¦ç»„åˆåˆ†æ")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        self.progress.start()
        thread = threading.Thread(target=self._generate_char_mapping_thread)
        thread.daemon = True
        thread.start()
    
    def _generate_char_mapping_thread(self):
        """åœ¨åå°çº¿ç¨‹ä¸­ç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨"""
        try:
            # æ¸…ç©ºç°æœ‰çš„å­—ç¬¦æ˜ å°„è¡¨
            self.char_mapping = {}
            
            # éå†æ‰€æœ‰åˆ†ææ•°æ®ï¼Œæ”¶é›†å­—ç¬¦å’Œå¯¹åº”çš„æ•°å€¼
            for analysis in self.analysis_data:
                # ä»å­—ç¬¦ç»„åˆåˆ—è§£æå‡ºå­—ç¬¦å’Œæ•°å€¼
                char_combination = analysis['å­—ç¬¦ç»„åˆ']
                values_str = analysis['æ•°å€¼']
                
                # è§£æå­—ç¬¦ç»„åˆ
                chars = re.findall(r"'([^']*)'", char_combination)
                # è§£ææ•°å€¼
                values = [int(x.strip()) for x in values_str.split('+')]
                
                # ç¡®ä¿å­—ç¬¦å’Œæ•°å€¼æ•°é‡åŒ¹é…
                if len(chars) != len(values):
                    continue
                    
                # å°†å­—ç¬¦å’Œæ•°å€¼å¯¹åº”èµ·æ¥
                for char, value in zip(chars, values):
                    if char not in self.char_mapping:
                        self.char_mapping[char] = []
                    if value not in self.char_mapping[char]:
                        self.char_mapping[char].append(value)
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_char_mapping_results)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"ç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨æ—¶å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _update_char_mapping_results(self):
        """æ›´æ–°å­—ç¬¦æ˜ å°„è¡¨ç»“æœ"""
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.char_mapping_tree.get_children():
            self.char_mapping_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        char_id = 1
        for char, values in sorted(self.char_mapping.items()):
            # æ ¼å¼åŒ–æ•°å€¼åˆ—è¡¨
            values_str = '/'.join(map(str, sorted(values)))
            count = len(values)
            
            self.char_mapping_tree.insert('', 'end', values=(
                char_id, char, values_str, count
            ))
            char_id += 1
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        if self.char_mapping:
            total_chars = len(self.char_mapping)
            total_mappings = sum(len(values) for values in self.char_mapping.values())
            max_values_char = max(self.char_mapping.items(), key=lambda x: len(x[1]))[0]
            max_values_count = len(self.char_mapping[max_values_char])
            
            stats_text = f"æ€»å­—ç¬¦æ•°: {total_chars}\næ€»æ˜ å°„æ•°: {total_mappings}\næœ€å¤šæ•°å€¼å­—ç¬¦: {max_values_char}({max_values_count})"
            self.char_mapping_stats_var.set(stats_text)
        
        messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸç”Ÿæˆå­—ç¬¦æ˜ å°„è¡¨ï¼Œå…± {len(self.char_mapping)} ä¸ªå­—ç¬¦ï¼")

    def browse_file(self):
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
            filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
        )
        if filename:
            self.file_path_var.set(filename)
    
    def extract_sentences(self):
        file_path = self.file_path_var.get()
        if not file_path or not os.path.exists(file_path):
            messagebox.showerror("é”™è¯¯", "è¯·é€‰æ‹©æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæå–ï¼Œé¿å…ç•Œé¢å¡é¡¿
        self.progress.start()
        thread = threading.Thread(target=self._extract_sentences_thread, args=(file_path,))
        thread.daemon = True
        thread.start()
    
    def _extract_sentences_thread(self, file_path):
        try:
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding='utf-8') as file:
                content = file.read()
            
            # è§£ææ–‡æ¡£
            sentences = self.parse_document(content)
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_extract_results, sentences)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _update_extract_results(self, sentences):
        self.sentences = sentences
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.extract_tree.get_children():
            self.extract_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for seq, sentence in sentences:
            length = len(sentence)
            self.extract_tree.insert('', 'end', values=(seq, sentence, length))
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        if sentences:
            df = pd.DataFrame(sentences, columns=['åºå·', 'å¥å­'])
            df['é•¿åº¦'] = df['å¥å­'].str.len()
            
            stats_text = f"æ€»å¥å­æ•°: {len(df)}\nå¹³å‡é•¿åº¦: {df['é•¿åº¦'].mean():.1f}\næœ€é•¿å¥å­: {df['é•¿åº¦'].max()}\næœ€çŸ­å¥å­: {df['é•¿åº¦'].min()}"
            self.stats_text.set(stats_text)
            
            messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸæå– {len(sentences)} ä¸ªå¥å­ï¼")
        else:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¥å­")
    
    def generate_analysis(self):
        if not self.sentences:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
            return
        
        try:
            start_seq = int(self.start_seq_var.get())
            end_seq = int(self.end_seq_var.get())
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†æ
        self.progress.start()
        thread = threading.Thread(target=self._generate_analysis_thread, args=(start_seq, end_seq))
        thread.daemon = True
        thread.start()
    
    def _generate_analysis_thread(self, start_seq, end_seq):
        try:
            # è¿‡æ»¤å¥å­
            filtered_sentences = [s for s in self.sentences if start_seq <= s[0] <= end_seq]
            
            if not filtered_sentences:
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¥å­"))
                return
            
            # ç”Ÿæˆåˆ†æç»“æœ
            analysis_data = []
            
            for seq, sentence in filtered_sentences:
                length = len(sentence)
                char_values = self.assign_values(sentence)
                
                # æ„å»ºå­—ç¬¦ç»„åˆå­—ç¬¦ä¸²
                char_combination = ' + '.join([f"'{char}'" for char, _ in char_values])
                
                # æ„å»ºæ•°å€¼å­—ç¬¦ä¸²
                values_str = ' + '.join([f"{val}" for _, val in char_values])
                
                # éªŒè¯æ€»å’Œ
                total = sum(val for _, val in char_values)
                
                analysis_data.append({
                    'åºå·': seq,
                    'å¥å­': sentence,
                    'é•¿åº¦': length,
                    'å­—ç¬¦ç»„åˆ': char_combination,
                    'æ•°å€¼': values_str,
                    'æ€»å’ŒéªŒè¯': total
                })
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_analysis_results, analysis_data, filtered_sentences)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _update_analysis_results(self, analysis_data, filtered_sentences):
        self.analysis_data = analysis_data
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.analysis_tree.get_children():
            self.analysis_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for data in analysis_data:
            self.analysis_tree.insert('', 'end', values=(
                data['åºå·'], data['å¥å­'], data['é•¿åº¦'],
                data['å­—ç¬¦ç»„åˆ'], data['æ•°å€¼'], data['æ€»å’ŒéªŒè¯']
            ))
        
        # æ›´æ–°ç¤ºä¾‹æ ‡ç­¾é¡µ
        if filtered_sentences:
            self._update_example_tab(filtered_sentences[0])
        
        messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸåˆ†æ {len(analysis_data)} ä¸ªå¥å­ï¼")
    
    def _update_example_tab(self, example_sentence):
        seq, sentence = example_sentence
        char_values = self.assign_values(sentence)
        
        # æ›´æ–°ç¤ºä¾‹ä¿¡æ¯
        info_text = f"ç¤ºä¾‹å¥å­ {seq}: {sentence}\né•¿åº¦: {len(sentence)} ä¸ªå­—ç¬¦"
        self.example_info_var.set(info_text)
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.example_tree.get_children():
            self.example_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for char, value in char_values:
            self.example_tree.insert('', 'end', values=(char, value))
    
    def generate_words_analysis(self):
        if not self.sentences:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
            return
        
        try:
            start_seq = int(self.words_start_seq_var.get())
            end_seq = int(self.words_end_seq_var.get())
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†è¯åˆ†æ
        self.progress.start()
        thread = threading.Thread(target=self._generate_words_analysis_thread, args=(start_seq, end_seq))
        thread.daemon = True
        thread.start()
    
    def _generate_words_analysis_thread(self, start_seq, end_seq):
        try:
            # è¿‡æ»¤å¥å­
            filtered_sentences = [s for s in self.sentences if start_seq <= s[0] <= end_seq]
            
            if not filtered_sentences:
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¥å­"))
                return
            
            # ä½¿ç”¨ç®€å•çš„åˆ†è¯æ–¹æ³•ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼‰
            words_data = []
            word_freq = {}
            word_sources = {}
            
            for seq, sentence in filtered_sentences:
                # ä½¿ç”¨ç®€å•çš„åˆ†è¯ï¼šæŒ‰éæ–‡å­—å­—ç¬¦åˆ†å‰²
                words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+', sentence)
                
                for word in words:
                    if len(word) > 1:  # åªä¿ç•™é•¿åº¦å¤§äº1çš„è¯è¯­
                        # æ›´æ–°è¯é¢‘
                        word_freq[word] = word_freq.get(word, 0) + 1
                        
                        # è®°å½•è¯è¯­æ¥æº
                        if word not in word_sources:
                            word_sources[word] = []
                        if seq not in word_sources[word]:
                            word_sources[word].append(seq)
            
            # æ„å»ºè¯è¯­æ•°æ®
            word_id = 1
            for word, freq in sorted(word_freq.items(), key=lambda x: x[1], reverse=True):
                sources = word_sources[word]
                source_text = f"å¥å­: {', '.join(map(str, sources[:3]))}" + ("..." if len(sources) > 3 else "")
                
                # è®¡ç®—è¯è¯­çš„å­—ç¬¦é•¿åº¦
                char_length = len(word)
                
                words_data.append({
                    'åºå·': word_id,
                    'è¯è¯­': word,
                    'å­—ç¬¦é•¿åº¦': char_length,
                    'è¯é¢‘': freq,
                    'å¥å­æ¥æº': source_text
                })
                word_id += 1
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_words_analysis_results, words_data, filtered_sentences)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"åˆ†è¯åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _update_words_analysis_results(self, words_data, filtered_sentences):
        self.words_data = words_data
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.words_tree.get_children():
            self.words_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for data in words_data:
            self.words_tree.insert('', 'end', values=(
                data['åºå·'], 
                data['è¯è¯­'], 
                data['å­—ç¬¦é•¿åº¦'],
                data['è¯é¢‘'], 
                data['å¥å­æ¥æº']
            ))
        
        # æ›´æ–°è¯è¯­ç»Ÿè®¡ä¿¡æ¯
        if words_data:
            total_words = sum(data['è¯é¢‘'] for data in words_data)
            unique_words = len(words_data)
            avg_length = sum(data['å­—ç¬¦é•¿åº¦'] for data in words_data) / unique_words
            
            # æ·»åŠ å­—ç¬¦é•¿åº¦åˆ†å¸ƒç»Ÿè®¡
            length_distribution = {}
            for data in words_data:
                length = data['å­—ç¬¦é•¿åº¦']
                length_distribution[length] = length_distribution.get(length, 0) + 1
            
            # æ‰¾å‡ºæœ€å¸¸è§çš„é•¿åº¦
            most_common_length = max(length_distribution.items(), key=lambda x: x[1])[0] if length_distribution else 0
            
            stats_text = f"æ€»è¯è¯­æ•°: {total_words}\nå”¯ä¸€è¯è¯­æ•°: {unique_words}\nå¹³å‡è¯è¯­é•¿åº¦: {avg_length:.1f}\næœ€å¸¸è§é•¿åº¦: {most_common_length}å­—ç¬¦"
            self.words_stats_var.set(stats_text)
        
        messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸåˆ†æ {len(filtered_sentences)} ä¸ªå¥å­ï¼Œæå– {len(words_data)} ä¸ªå”¯ä¸€è¯è¯­ï¼")
    
    def generate_words_value_analysis(self):
        if not self.sentences:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
            return
        
        try:
            start_seq = int(self.words_value_start_seq_var.get())
            end_seq = int(self.words_value_end_seq_var.get())
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„åºå·")
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè¯è¯­æ•°å€¼åˆ†é…åˆ†æ
        self.progress.start()
        thread = threading.Thread(target=self._generate_words_value_analysis_thread, args=(start_seq, end_seq))
        thread.daemon = True
        thread.start()
    
    def _generate_words_value_analysis_thread(self, start_seq, end_seq):
        try:
            # è¿‡æ»¤å¥å­
            filtered_sentences = [s for s in self.sentences if start_seq <= s[0] <= end_seq]
            
            if not filtered_sentences:
                self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", "æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¥å­"))
                return
            
            # ç”Ÿæˆè¯è¯­æ•°å€¼åˆ†é…ç»“æœ
            words_value_data = []
            
            for seq, sentence in filtered_sentences:
                # ä½¿ç”¨åˆ†è¯å°†å¥å­åˆ†æˆè¯è¯­
                words = self.tokenize_sentence(sentence)
                
                # å¯¹è¯è¯­åˆ—è¡¨åº”ç”¨æ•°å€¼åˆ†é…è§„åˆ™
                word_values = self.assign_values_to_list(words)
                
                # æ„å»ºè¯è¯­ç»„åˆå­—ç¬¦ä¸²
                word_combination = ' + '.join([f"'{word}'" for word, _ in word_values])
                
                # æ„å»ºæ•°å€¼å­—ç¬¦ä¸²
                values_str = ' + '.join([f"{val}" for _, val in word_values])
                
                # éªŒè¯æ€»å’Œ
                total = sum(val for _, val in word_values)
                
                words_value_data.append({
                    'åºå·': seq,
                    'å¥å­': sentence,
                    'è¯è¯­æ•°é‡': len(words),
                    'è¯è¯­ç»„åˆ': word_combination,
                    'æ•°å€¼': values_str,
                    'æ€»å’ŒéªŒè¯': total
                })
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self._update_words_value_analysis_results, words_value_data, filtered_sentences)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"è¯è¯­æ•°å€¼åˆ†é…åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {e}"))
        finally:
            self.root.after(0, self.progress.stop)
    
    def _update_words_value_analysis_results(self, words_value_data, filtered_sentences):
        self.words_value_data = words_value_data
        
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.words_value_tree.get_children():
            self.words_value_tree.delete(item)
        
        # æ·»åŠ æ–°æ•°æ®
        for data in words_value_data:
            self.words_value_tree.insert('', 'end', values=(
                data['åºå·'], 
                data['å¥å­'], 
                data['è¯è¯­æ•°é‡'],
                data['è¯è¯­ç»„åˆ'], 
                data['æ•°å€¼'], 
                data['æ€»å’ŒéªŒè¯']
            ))
        
        messagebox.showinfo("æˆåŠŸ", f"æˆåŠŸåˆ†æ {len(words_value_data)} ä¸ªå¥å­çš„è¯è¯­æ•°å€¼åˆ†é…ï¼")
    
    def tokenize_sentence(self, sentence):
        """å°†å¥å­åˆ†æˆè¯è¯­"""
        # ä½¿ç”¨ç®€å•çš„åˆ†è¯ï¼šæŒ‰éæ–‡å­—å­—ç¬¦åˆ†å‰²
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+|\d+|[^\s\w]', sentence)
        return words
    
    def assign_values_to_list(self, items):
        """ä¸ºåˆ—è¡¨ä¸­çš„é¡¹ç›®åˆ†é…æ•°å€¼ï¼ˆä½¿ç”¨ä¸å­—ç¬¦ç»„åˆç›¸åŒçš„è§„åˆ™ï¼‰"""
        n = len(items)
        
        if n == 0:
            return []
        
        if n == 1:
            # å•ä¸ªé¡¹ç›®ï¼Œå€¼=100
            return [(items[0], 100)]
        
        if n == 2:
            # ä¸¤ä¸ªé¡¹ç›®ï¼Œç¬¬ä¸€ä¸ª=0ï¼Œç¬¬äºŒä¸ª=100
            return [(items[0], 0), (items[1], 100)]
        
        # n >= 3 çš„æƒ…å†µ
        # ç”Ÿæˆé€’å¢çš„å·®å€¼ - ä¿®æ”¹ä¸ºå®Œå…¨éšæœº
        deltas = [random.randint(1, 5) for _ in range(n - 1)]  # æ‰©å¤§éšæœºèŒƒå›´
        
        # æ„å»ºæ•°å€¼åºåˆ—
        values = [0]  # ç¬¬ä¸€ä¸ªé¡¹ç›®æ€»æ˜¯0
        for d in deltas:
            values.append(values[-1] + d)
        
        # è®¡ç®—å½“å‰æ€»å’Œ
        current_sum = sum(values)
        remaining = 100 - current_sum
        
        # å°†å‰©ä½™å€¼åŠ åˆ°æœ€åä¸€ä¸ªé¡¹ç›®
        values[-1] += remaining
        
        return list(zip(items, values))
    
    def save_analysis(self):
        if not self.analysis_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„åˆ†ææ•°æ®")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜åˆ†æç»“æœ",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                df = pd.DataFrame(self.analysis_data)
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                messagebox.showinfo("æˆåŠŸ", f"åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_words_analysis(self):
        if not self.words_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„è¯è¯­æ•°æ®")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜è¯è¯­åˆ†æç»“æœ",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                df = pd.DataFrame(self.words_data)
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                messagebox.showinfo("æˆåŠŸ", f"è¯è¯­åˆ†æç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_words_value_analysis(self):
        if not hasattr(self, 'words_value_data') or not self.words_value_data:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„è¯è¯­æ•°å€¼åˆ†é…æ•°æ®")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜è¯è¯­æ•°å€¼åˆ†é…ç»“æœ",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                df = pd.DataFrame(self.words_value_data)
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                messagebox.showinfo("æˆåŠŸ", f"è¯è¯­æ•°å€¼åˆ†é…ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_char_mapping(self):
        """ä¿å­˜å­—ç¬¦æ˜ å°„è¡¨"""
        if not self.char_mapping:
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å­—ç¬¦æ˜ å°„è¡¨æ•°æ®")
            return
        
        filename = filedialog.asksaveasfilename(
            title="ä¿å­˜å­—ç¬¦æ˜ å°„è¡¨",
            defaultextension=".csv",
            filetypes=[("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if filename:
            try:
                # æ„å»ºæ•°æ®æ¡†
                data = []
                char_id = 1
                for char, values in sorted(self.char_mapping.items()):
                    values_str = '/'.join(map(str, sorted(values)))
                    count = len(values)
                    data.append({
                        'åºå·': char_id,
                        'å­—ç¬¦': char,
                        'æ•°å€¼åˆ—è¡¨': values_str,
                        'å‡ºç°æ¬¡æ•°': count
                    })
                    char_id += 1
                
                df = pd.DataFrame(data)
                df.to_csv(filename, index=False, encoding='utf-8-sig')
                messagebox.showinfo("æˆåŠŸ", f"å­—ç¬¦æ˜ å°„è¡¨å·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # åŸæœ‰çš„è§£æå’Œåˆ†é…æ•°å€¼å‡½æ•°
    def parse_document(self, content: str) -> List[Tuple[int, str]]:
        """è§£ææ–‡æ¡£ï¼Œæå–åºå·å’Œå¥å­"""
        sentences = []
        lines = content.strip().split('\n')
        
        for line in lines:
            # åŒ¹é… "åºå·. å¥å­" æ ¼å¼
            match = re.match(r'^(\d+)\.\s+(.+)$', line.strip())
            if match:
                seq_num = int(match.group(1))
                sentence = match.group(2).strip()
                # è¿‡æ»¤æ‰ç©ºå¥å­å’Œç‰¹æ®Šæ ‡è®°è¡Œ
                if sentence and not sentence.startswith('ç”Ÿæˆæ—¶é—´:') and not sentence.startswith('#'):
                    sentences.append((seq_num, sentence))
        
        return sentences
    
    def assign_values(self, s: str) -> List[Tuple[str, int]]:
        """ä¸ºå¥å­ä¸­çš„æ¯ä¸ªå­—ç¬¦åˆ†é…æ•°å€¼ - ä¸¥æ ¼æŒ‰ç…§æ‚¨å®šä¹‰çš„è§„åˆ™"""
        n = len(s)
        
        if n == 0:
            return []
        
        if n == 1:
            # å•ä¸ªå­—ç¬¦ï¼Œå€¼=100
            return [(s[0], 100)]
        
        if n == 2:
            # ä¸¤ä¸ªå­—ç¬¦ï¼Œç¬¬ä¸€ä¸ª=0ï¼Œç¬¬äºŒä¸ª=100
            return [(s[0], 0), (s[1], 100)]
        
        # n >= 3 çš„æƒ…å†µ
        # ç”Ÿæˆé€’å¢çš„å·®å€¼
        deltas = [random.randint(1, 5) for _ in range(n - 1)]
        
        # æ„å»ºæ•°å€¼åºåˆ—
        values = [0]  # ç¬¬ä¸€ä¸ªå­—ç¬¦æ€»æ˜¯0
        for d in deltas:
            values.append(values[-1] + d)
        
        # è®¡ç®—å½“å‰æ€»å’Œ
        current_sum = sum(values)
        remaining = 100 - current_sum
        
        # å°†å‰©ä½™å€¼åŠ åˆ°æœ€åä¸€ä¸ªå­—ç¬¦
        values[-1] += remaining
        
        return list(zip(s, values))
    
    # å›¾è¡¨ç›¸å…³æ–¹æ³•
    def generate_char_chart(self):
        """ç”Ÿæˆå­—ç¬¦æ•°å€¼å›¾è¡¨"""
        if not self.sentences:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
            return
        
        try:
            seq = int(self.chart_seq_var.get())
        except ValueError:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥æœ‰æ•ˆçš„å¥å­åºå·")
            return
        
        # æŸ¥æ‰¾æŒ‡å®šåºå·çš„å¥å­
        target_sentence = None
        for s in self.sentences:
            if s[0] == seq:
                target_sentence = s
                break
        
        if not target_sentence:
            messagebox.showerror("é”™è¯¯", f"æœªæ‰¾åˆ°åºå·ä¸º {seq} çš„å¥å­")
            return
        
        # ç”Ÿæˆå­—ç¬¦æ•°å€¼åˆ†é…
        char_values = self.assign_values(target_sentence[1])
        
        # åˆ›å»ºå›¾è¡¨
        self._create_char_value_chart(target_sentence, char_values)
    
    def _create_char_value_chart(self, sentence, char_values):
        """åˆ›å»ºå­—ç¬¦æ•°å€¼å›¾è¡¨"""
        # æ¸…é™¤ç°æœ‰å›¾è¡¨
        self._clear_chart()
        
        # åˆ›å»ºplotlyå›¾è¡¨
        seq, text = sentence
        chars = [cv[0] for cv in char_values]
        values = [cv[1] for cv in char_values]
        
        fig = go.Figure(data=[
            go.Bar(x=chars, y=values, marker_color='skyblue')
        ])
        
        fig.update_layout(
            title=dict(
                text=f'å¥å­ {seq} å­—ç¬¦æ•°å€¼åˆ†å¸ƒ: "{text}"',
                font=dict(size=14)
            ),
            xaxis_title='å­—ç¬¦',
            yaxis_title='æ•°å€¼',
            showlegend=False
        )
        
        # ä¿å­˜ä¸ºHTMLæ–‡ä»¶å¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        html_path = tempfile.NamedTemporaryFile(suffix='.html', delete=False).name
        pyo.plot(fig, filename=html_path, auto_open=True)
        
        self.chart_status_var.set("å›¾è¡¨å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
    
    def generate_length_chart(self):
        """ç”Ÿæˆå¥å­é•¿åº¦åˆ†å¸ƒå›¾è¡¨"""
        if not self.sentences:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆæå–å¥å­")
            return
        
        # è®¡ç®—å¥å­é•¿åº¦åˆ†å¸ƒ
        lengths = [len(s[1]) for s in self.sentences]
        
        # åˆ›å»ºå›¾è¡¨
        self._create_length_distribution_chart(lengths)
    
    def _create_length_distribution_chart(self, lengths):
        """åˆ›å»ºå¥å­é•¿åº¦åˆ†å¸ƒå›¾è¡¨"""
        # è®¡ç®—é¢‘ç‡
        length_counts = {}
        for length in lengths:
            length_counts[length] = length_counts.get(length, 0) + 1
        
        # æ’åº
        sorted_lengths = sorted(length_counts.keys())
        counts = [length_counts[length] for length in sorted_lengths]
        
        # åˆ›å»ºplotlyå›¾è¡¨
        fig = go.Figure(data=[
            go.Bar(x=sorted_lengths, y=counts, marker_color='lightgreen')
        ])
        
        fig.update_layout(
            title=dict(
                text='å¥å­é•¿åº¦åˆ†å¸ƒ',
                font=dict(size=14)
            ),
            xaxis_title='å¥å­é•¿åº¦',
            yaxis_title='å¥å­æ•°é‡',
            showlegend=False
        )
        
        # ä¿å­˜ä¸ºHTMLæ–‡ä»¶å¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        html_path = tempfile.NamedTemporaryFile(suffix='.html', delete=False).name
        pyo.plot(fig, filename=html_path, auto_open=True)
        
        self.chart_status_var.set("å›¾è¡¨å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
    
    def generate_word_freq_chart(self):
        """ç”Ÿæˆè¯è¯­é¢‘ç‡å›¾è¡¨"""
        if not hasattr(self, 'words_data') or not self.words_data:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆè¿›è¡Œè¯è¯­åˆ†æ")
            return
        
        # è·å–å‰20ä¸ªæœ€é¢‘ç¹çš„è¯è¯­
        top_words = self.words_data[:20]
        
        # åˆ›å»ºå›¾è¡¨
        self._create_word_frequency_chart(top_words)
    
    def _create_word_frequency_chart(self, top_words):
        """åˆ›å»ºè¯è¯­é¢‘ç‡å›¾è¡¨"""
        words = [w['è¯è¯­'] for w in top_words]
        freqs = [w['è¯é¢‘'] for w in top_words]
        
        # åˆ›å»ºplotlyå›¾è¡¨
        fig = go.Figure(data=[
            go.Bar(y=words, x=freqs, orientation='h', marker_color='lightcoral')
        ])
        
        fig.update_layout(
            title=dict(
                text='Top 20 è¯è¯­é¢‘ç‡åˆ†å¸ƒ',
                font=dict(size=14)
            ),
            xaxis_title='é¢‘ç‡',
            yaxis_title='è¯è¯­',
            showlegend=False
        )
        
        # ä¿å­˜ä¸ºHTMLæ–‡ä»¶å¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
        html_path = tempfile.NamedTemporaryFile(suffix='.html', delete=False).name
        pyo.plot(fig, filename=html_path, auto_open=True)
        
        self.chart_status_var.set("å›¾è¡¨å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
    
    def _clear_chart(self):
        """æ¸…é™¤å½“å‰å›¾è¡¨"""
        # å¯¹äºplotlyï¼Œæˆ‘ä»¬ä¸éœ€è¦æ¸…é™¤ï¼Œå› ä¸ºæ¯æ¬¡éƒ½åœ¨æ–°æ–‡ä»¶ä¸­ç”Ÿæˆ
        pass
    
    def save_chart(self):
        """ä¿å­˜å½“å‰å›¾è¡¨"""
        messagebox.showinfo("æç¤º", "å›¾è¡¨å·²è‡ªåŠ¨ä¿å­˜ä¸ºHTMLæ–‡ä»¶å¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œæ‚¨å¯ä»¥åœ¨æµè§ˆå™¨ä¸­ç›´æ¥ä¿å­˜å›¾è¡¨")

def main():
    root = tk.Tk()
    app = DocumentAnalyzerApp(root)
    root.mainloop()

if __name__ == "__main__":
    main()