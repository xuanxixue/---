# ---
é“è¡ç®—æ³•-ç±»äººæ€è€ƒçš„ç¥ç»ç½‘ç»œç®—æ³•

ğŸ“Š æ–°å¢ç¬¬å…«ç« ï¼šå®éªŒéªŒè¯ä¸æ€§èƒ½è¯„ä¼°
8.1 å®éªŒè®¾è®¡åŸºç¡€
8.1.1 æ•°æ®é›†é€‰æ‹©
ä¸­æ–‡æ–‡æœ¬æ•°æ®é›†ï¼šé‡‡ç”¨ã€Œä¸­æ–‡é€šç”¨è¯­æ–™åº“ï¼ˆCCLï¼‰ã€+ã€Œè‡ªå®šä¹‰é¢†åŸŸè¯­æ–™ï¼ˆæ•™è‚² / åŒ»ç–—ï¼‰ã€ï¼Œæ€»è§„æ¨¡ 100 ä¸‡å¥ï¼Œæ¶µç›–å¸¸è¯†ç±»ï¼ˆ60%ï¼‰ã€ä¸“ä¸šç±»ï¼ˆ30%ï¼‰ã€åˆ›é€ æ€§æ–‡æœ¬ï¼ˆ10%ï¼‰
å¯¹æ¯”åŸºå‡†ï¼šGPT-3.5ï¼ˆAPI è°ƒç”¨ï¼‰ã€é€šä¹‰åƒé—® - 7Bï¼ˆæœ¬åœ°éƒ¨ç½²ï¼‰ã€ä¼ ç»Ÿè§„åˆ™æ¨ç†ç³»ç»Ÿ
8.1.2 æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡
æŒ‡æ ‡ç±»å‹
å…·ä½“æŒ‡æ ‡
è®¡ç®—æ–¹å¼
å¯è§£é‡Šæ€§
è·¯å¾„å¯è§†åŒ–ç‡
å¯è¿½æº¯æ¨ç†è·¯å¾„çš„è¾“å‡ºå æ¯”ï¼ˆç›®æ ‡ 100%ï¼‰
å¯æ§æ€§
å½’å±å‡†ç¡®ç‡
æ–°å†…å®¹æ­£ç¡®å½’ç±»åˆ°å¸¸è¯† / è¡ç”Ÿ / å¹»æƒ³å±‚çš„æ¯”ä¾‹ï¼ˆç›®æ ‡â‰¥90%ï¼‰
åˆ›é€ æ€§
æ–°é¢–åº¦å¾—åˆ†
ä¸è®­ç»ƒæ•°æ®çš„ NCD ç›¸ä¼¼åº¦â‰¤0.3 çš„è¾“å‡ºå æ¯”ï¼ˆç›®æ ‡â‰¥30%ï¼‰
å®‰å…¨æ€§
å¹»è§‰ç‡
è™šå‡ä¿¡æ¯è¾“å‡ºå æ¯”ï¼ˆç›®æ ‡â‰¤1%ï¼‰
æ€§èƒ½
æ¨ç†é€Ÿåº¦
å•å¥å¤„ç†è€—æ—¶ï¼ˆç›®æ ‡â‰¤500msï¼‰ï¼›10 ä¸‡å¥å»ºå›¾æ—¶é—´ï¼ˆç›®æ ‡â‰¤2 å°æ—¶ï¼‰
èµ„æºæ¶ˆè€—
å†…å­˜å ç”¨
10 ä¸‡å¥æ€ç»´å›¾å†…å­˜å ç”¨ï¼ˆç›®æ ‡â‰¤2GBï¼‰ï¼›GPU æ˜¾å­˜éœ€æ±‚ï¼ˆç›®æ ‡â‰¤4GBï¼ŒCPU å¯è¿è¡Œï¼‰

8.2 å®éªŒç»“æœä¸åˆ†æ
8.2.1 æ ¸å¿ƒèƒ½åŠ›å¯¹æ¯”ï¼ˆè¡¨ 1ï¼‰
ç³»ç»Ÿ
è·¯å¾„å¯è§†åŒ–ç‡
å½’å±å‡†ç¡®ç‡
æ–°é¢–åº¦å¾—åˆ†
å¹»è§‰ç‡
å•å¥å¤„ç†è€—æ—¶
10 ä¸‡å¥å†…å­˜å ç”¨
GPT-3.5
0%
ä¸å¯æ§
28%
3.2%
800ms
-ï¼ˆäº‘ç«¯æ— æœ¬åœ°ï¼‰
é€šä¹‰åƒé—® - 7B
0%
ä¸å¯æ§
25%
2.8%
1200ms
12GB
ä¼ ç»Ÿè§„åˆ™æ¨ç†ç³»ç»Ÿ
100%
85%
5%
0.5%
300ms
1.2GB
æœ¬ç³»ç»Ÿï¼ˆFD-NTGï¼‰
100%
92%
35%
0.8%
420ms
1.8GB

8.2.2 å…³é”®ç»“è®º
å¯è§£é‡Šæ€§ï¼šæœ¬ç³»ç»Ÿå®ç° 100% è·¯å¾„å¯è§†åŒ–ï¼Œå½»åº•è§£å†³å¤§æ¨¡å‹é»‘ç®±é—®é¢˜
å¯æ§æ€§ï¼šå½’å±å‡†ç¡®ç‡è¶… 90%ï¼Œæ”¯æŒé€šè¿‡è°ƒæ•´è¯„åˆ†æƒé‡ï¼ˆå¦‚å°†ã€Œå¸¸è¯†ä¸€è‡´æ€§ã€æƒé‡ä» 0.3 è°ƒè‡³ 0.5ï¼‰è¿›ä¸€æ­¥é™ä½å¹»è§‰ç‡è‡³ 0.5% ä»¥ä¸‹
åˆ›é€ æ€§ï¼šæ–°é¢–åº¦å¾—åˆ†é«˜äºå¤§æ¨¡å‹ï¼Œä¸”æ”¯æŒã€Œå¹»æƒ³å±‚å¼ºåº¦è°ƒèŠ‚ã€ï¼ˆå¦‚ GAN ç”Ÿæˆæ¸©åº¦å‚æ•°ä» 1.0 è°ƒè‡³ 1.5ï¼Œæ–°é¢–åº¦å¯æå‡è‡³ 45%ï¼‰
è½»é‡æ€§ï¼šå†…å­˜å ç”¨ä»…ä¸ºé€šä¹‰åƒé—® - 7B çš„ 15%ï¼ŒCPU ç¯å¢ƒä¸‹å¯è¿è¡Œï¼ˆè€—æ—¶å¢åŠ è‡³ 800ms / å¥ï¼‰
8.3 é¢†åŸŸé€‚é…å®éªŒï¼ˆæ•™è‚²åœºæ™¯ç¤ºä¾‹ï¼‰
å®éªŒä»»åŠ¡ï¼šæ„å»ºã€Œå°å­¦æ•°å­¦æ€ç»´å›¾ã€ï¼Œå¤„ç† 10 ä¸‡é“æ•°å­¦é¢˜æ–‡æœ¬æè¿°
å®šåˆ¶åŒ–è°ƒæ•´ï¼š
å¸¸è¯†å±‚ï¼šæ·»åŠ ã€Œæ•°å­¦å…¬å¼æ¨¡æ¿ï¼ˆå¦‚ S=Ï€rÂ²ï¼‰ã€ã€Œå•ä½æ¢ç®—è§„åˆ™ã€
è¡ç”Ÿå±‚ï¼šå¼ºåŒ–ã€Œé€»è¾‘æ¨ç†é“¾ï¼ˆå¦‚åº”ç”¨é¢˜åˆ†æ­¥æ¨å¯¼ï¼‰ã€
è¯„åˆ†æœºåˆ¶ï¼šå¢åŠ ã€Œå…¬å¼æ­£ç¡®æ€§æƒé‡ï¼ˆ0.4ï¼‰ã€
ç»“æœï¼šæ•°å­¦é¢˜æ¨ç†å‡†ç¡®ç‡ 94%ï¼Œæ­¥éª¤å¯è§†åŒ–ç‡ 100%ï¼Œæ”¯æŒå­¦ç”Ÿè¿½æº¯è§£é¢˜æ€è·¯

ğŸ–¼ï¸ æ–°å¢ç¬¬ä¹ç« ï¼šå¤šæ¨¡æ€æ‰©å±•å…·ä½“æ–¹æ¡ˆ
9.1 å¤šæ¨¡æ€èŠ‚ç‚¹å®šä¹‰ä¸è¡¨ç¤º
9.1.1 èŠ‚ç‚¹ç±»å‹æ‰©å±•
æ¨¡æ€ç±»å‹
èŠ‚ç‚¹ç»“æ„
ç‰¹å¾æå–ç®—æ³•
ç¤ºä¾‹
å›¾åƒ
(img_id, feature_vec, label)
ResNet-50ï¼ˆæå– 2048 ç»´ç‰¹å¾ï¼‰
img_001ï¼šçŒ«çš„å›¾ç‰‡ â†’ ç‰¹å¾å‘é‡ +ã€ŒçŒ«ã€æ ‡ç­¾
éŸ³é¢‘
(audio_id, mel_vec, text_trans)
Wav2Vec2ï¼ˆæå– 768 ç»´ Mel ç‰¹å¾ï¼‰
audio_001ï¼šçŒ«å«éŸ³é¢‘ â†’ ç‰¹å¾å‘é‡ +ã€ŒçŒ«å«ã€æ–‡æœ¬
è§†é¢‘
(video_id, frame_features, text)
æ¯ 10 å¸§ç”¨ ViT æå–ç‰¹å¾ + æ—¶åº LSTM
video_001ï¼šçŒ«èµ°è·¯è§†é¢‘ â†’ å¸§ç‰¹å¾ +ã€ŒçŒ«èµ°è·¯ã€æ–‡æœ¬

9.1.2 è·¨æ¨¡æ€æ˜ å°„æœºåˆ¶
# å¤šæ¨¡æ€ç‰¹å¾å¯¹é½ï¼šå°†å›¾åƒ/éŸ³é¢‘ç‰¹å¾æ˜ å°„åˆ°æ–‡æœ¬å‘é‡ç©ºé—´ï¼ˆBERT 768ç»´ï¼‰
class ModalAligner(nn.Module):
    def __init__(self, src_dim, tgt_dim=768):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(src_dim, 1024),
            nn.ReLU(),
            nn.Linear(1024, tgt_dim),
            nn.LayerNorm(tgt_dim)
        )
        # æ–‡æœ¬å‘é‡ç¼–ç å™¨ï¼ˆBERTï¼‰
        self.text_encoder = AutoModel.from_pretrained("bert-base-chinese")

    def forward(self, src_feature, text=None):
        # å¤šæ¨¡æ€ç‰¹å¾æ˜ å°„
        aligned_vec = self.fc(src_feature)
        if text is not None:
            # ä¸æ–‡æœ¬å‘é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œç”¨äºå¯¹é½æŸå¤±
            text_inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
            text_vec = self.text_encoder(**text_inputs).last_hidden_state[:, 0, :]
            align_loss = 1 - F.cosine_similarity(aligned_vec, text_vec).mean()
            return aligned_vec, align_loss
        return aligned_vec

9.2 è·¨æ¨¡æ€å› æœæ¡¥æ„å»º
9.2.1 æ¡¥æ¥è§„åˆ™è®¾è®¡
ç¡¬æ¡¥æ¥ï¼šåŸºäºæ ‡ç­¾åŒ¹é…ï¼ˆå¦‚å›¾åƒèŠ‚ç‚¹ã€ŒçŒ«ã€â†’ æ–‡æœ¬èŠ‚ç‚¹ã€ŒçŒ«ã€ï¼Œæƒé‡ 1.0ï¼‰
è½¯æ¡¥æ¥ï¼šåŸºäºç‰¹å¾ç›¸ä¼¼åº¦ï¼ˆå¦‚éŸ³é¢‘èŠ‚ç‚¹ã€ŒçŒ«å«ã€ä¸æ–‡æœ¬èŠ‚ç‚¹ã€ŒçŒ«ã€ï¼Œä½™å¼¦ç›¸ä¼¼åº¦ 0.8 â†’ æƒé‡ 0.8ï¼‰
å±‚çº§æ¡¥æ¥ï¼š
å›¾åƒ / éŸ³é¢‘ â†’ å¸¸è¯†å±‚ï¼šç›´æ¥å…³è”å·²çŸ¥æ ‡ç­¾ï¼ˆå¦‚ã€Œç‹—çš„å›¾ç‰‡ã€â†’ å¸¸è¯†å±‚ã€Œç‹—æ˜¯åŠ¨ç‰©ã€ï¼‰
è§†é¢‘ â†’ è¡ç”Ÿå±‚ï¼šåŸºäºæ—¶åºç‰¹å¾æ¨å¯¼ï¼ˆå¦‚ã€Œç‹—è¿½çƒè§†é¢‘ã€â†’ è¡ç”Ÿå±‚ã€Œç‹—å–œæ¬¢è¿åŠ¨ã€ï¼‰
9.2.2 å¤šæ¨¡æ€æ€ç»´å›¾ç¤ºä¾‹
# æ„å»ºå¤šæ¨¡æ€æ€ç»´å›¾
multi_modal_graph = nx.MultiDiGraph()

# æ·»åŠ æ–‡æœ¬èŠ‚ç‚¹ï¼ˆå¸¸è¯†å±‚ï¼‰
multi_modal_graph.add_node("text_çŒ«", type="text", layer="common", vec=text_vec_çŒ«)
# æ·»åŠ å›¾åƒèŠ‚ç‚¹
multi_modal_graph.add_node("img_çŒ«", type="image", layer="common", vec=img_vec_çŒ«)
# æ·»åŠ è·¨æ¨¡æ€å› æœæ¡¥
multi_modal_graph.add_edge(
    "img_çŒ«", "text_çŒ«", 
    bridge_type="causal", 
    weight=0.95, 
    similarity=0.95  # ä½™å¼¦ç›¸ä¼¼åº¦
)
# æ·»åŠ è§†é¢‘â†’è¡ç”Ÿå±‚æ¡¥æ¥
multi_modal_graph.add_edge(
    "video_ç‹—è¿½çƒ", "text_ç‹—å–œæ¬¢è¿åŠ¨", 
    bridge_type="causal", 
    layer="derive", 
    weight=0.8, 
    reason="è§†é¢‘æ—¶åºç‰¹å¾æ˜¾ç¤ºç‹—æŒç»­è¿½çƒ"
)


ğŸ–¥ï¸ æ–°å¢ç¬¬åç« ï¼šæ€ç»´ç½‘ OS æ¶æ„è®¾è®¡é›å½¢
10.1 OS æ ¸å¿ƒæ¨¡å—åˆ’åˆ†
æ¨¡å—åç§°
æ ¸å¿ƒåŠŸèƒ½
æŠ€æœ¯ä¾èµ–
ä»»åŠ¡è°ƒåº¦å™¨
è§£æç”¨æˆ·ä»»åŠ¡â†’åˆ†é…æ€ç»´å›¾å±‚èµ„æº
è§„åˆ™å¼•æ“ + å¼ºåŒ–å­¦ä¹ ï¼ˆä»»åŠ¡ä¼˜å…ˆçº§æ’åºï¼‰
çŸ¥è¯†ç®¡ç†å™¨
æ€ç»´å›¾å­˜å‚¨ / æ›´æ–° / åˆå¹¶ / å¤‡ä»½
SQLiteï¼ˆè½»é‡å­˜å‚¨ï¼‰+ å¢é‡åŒæ­¥ç®—æ³•
å¤šæ¨¡æ€äº¤äº’å±‚
æ¥æ”¶æ–‡æœ¬ / å›¾åƒ / éŸ³é¢‘è¾“å…¥â†’ç»Ÿä¸€ç¼–ç 
Gradioï¼ˆäº¤äº’ç•Œé¢ï¼‰+ å¤šæ¨¡æ€ç¼–ç å™¨
æ¨ç†å¼•æ“
è°ƒç”¨å››å±‚æ€ç»´å›¾è¿›è¡Œè·¯å¾„æ¨ç†
GNN è·¯å¾„æœç´¢ç®—æ³• + è¯„åˆ†æœºåˆ¶
æ’ä»¶æ‰©å±•æ¥å£
æ”¯æŒç¬¬ä¸‰æ–¹é¢†åŸŸæ’ä»¶ï¼ˆå¦‚åŒ»ç–— / æ•™è‚²ï¼‰
RESTful API + æ’ä»¶è®¤è¯æœºåˆ¶

10.2 OS å·¥ä½œæµç¨‹ï¼ˆç”¨æˆ·ä»»åŠ¡ç¤ºä¾‹ï¼šã€Œè§£ç­”å°å­¦æ•°å­¦é¢˜ï¼šåœ†åŠå¾„ 3cmï¼Œæ±‚é¢ç§¯ã€ï¼‰
ä»»åŠ¡è¾“å…¥ï¼šç”¨æˆ·é€šè¿‡äº¤äº’å±‚è¾“å…¥æ–‡æœ¬ + åœ†çš„ç¤ºæ„å›¾
ä»»åŠ¡è§£æï¼ˆè°ƒåº¦å™¨ï¼‰ï¼š
è¯†åˆ«ä»»åŠ¡ç±»å‹ï¼šã€Œæ•°å­¦è®¡ç®—ã€â†’ è°ƒç”¨ã€Œæ•™è‚²æ’ä»¶ã€
åˆ†é…èµ„æºï¼šä¼˜å…ˆä½¿ç”¨å¸¸è¯†å±‚ï¼ˆå…¬å¼ï¼‰+ è¡ç”Ÿå±‚ï¼ˆè®¡ç®—æ­¥éª¤ï¼‰
å¤šæ¨¡æ€ç¼–ç ï¼ˆäº¤äº’å±‚ï¼‰ï¼š
æ–‡æœ¬â†’BERT å‘é‡ï¼Œå›¾åƒâ†’ResNet å‘é‡
è·¨æ¨¡æ€æ¡¥æ¥ï¼šå›¾åƒã€Œåœ†ã€â†’ æ–‡æœ¬ã€Œåœ†ã€â†’ å¸¸è¯†å±‚ã€Œåœ†é¢ç§¯å…¬å¼ S=Ï€rÂ²ã€
æ¨ç†è¿‡ç¨‹ï¼ˆæ¨ç†å¼•æ“ï¼‰ï¼š
å¸¸è¯†å±‚è°ƒç”¨ï¼šæå–å…¬å¼ã€ŒS=Ï€rÂ²ã€ï¼ˆæƒé‡ 0.9ï¼‰
è¡ç”Ÿå±‚è®¡ç®—ï¼šr=3cm â†’ rÂ²=9 â†’ S=9Ï€â‰ˆ28.26cmÂ²ï¼ˆæ­¥éª¤å¯è§†åŒ–ï¼‰
è¯„åˆ†éªŒè¯ï¼šè®¡ç®—ç»“æœä¸å¸¸è¯†å±‚å…¬å¼ä¸€è‡´æ€§ 100% â†’ å½’å±å¸¸è¯†å±‚
ç»“æœè¾“å‡ºï¼šè¿”å›è®¡ç®—ç»“æœ + æ­¥éª¤å¯è§†åŒ–å›¾ + å…¬å¼æ¥æºæ ‡æ³¨
10.3 OS éƒ¨ç½²æ–¹æ¡ˆ
è½»é‡ç‰ˆï¼šWindows/macOS æœ¬åœ°éƒ¨ç½²ï¼ˆå•ç”¨æˆ·ï¼‰ï¼Œèµ„æºéœ€æ±‚ï¼šCPU i5+4GB å†…å­˜ + 10GB å­˜å‚¨
æœåŠ¡å™¨ç‰ˆï¼šLinux æœåŠ¡å™¨éƒ¨ç½²ï¼ˆå¤šç”¨æˆ·ï¼‰ï¼Œæ”¯æŒ 100 å¹¶å‘ï¼Œèµ„æºéœ€æ±‚ï¼šCPU Xeon E3+16GB å†…å­˜ + 100GB å­˜å‚¨
ç§»åŠ¨ç«¯é€‚é…ï¼šç²¾ç®€ç‰ˆæ€ç»´å›¾ï¼ˆä»…å¸¸è¯†å±‚ + æ ¸å¿ƒè¡ç”Ÿå±‚ï¼‰ï¼ŒAndroid/iOS ç«¯ï¼Œæ”¯æŒç¦»çº¿æ¨ç†

ğŸ’» æ–°å¢ç¬¬åä¸€ç« ï¼šæ ¸å¿ƒä»£ç è¡¥å……ï¼ˆå®Œæ•´å®ç°ï¼‰
11.1 GNN è·¯å¾„æ¨ç†å®Œæ•´ä»£ç ï¼ˆPyTorch Geometricï¼‰
import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool
from torch_geometric.data import Data, DataLoader

class PathGNN(nn.Module):
    """ç”¨äºæ€ç»´å›¾è·¯å¾„æ¨ç†çš„GCNæ¨¡å‹"""
    def __init__(self, in_channels, hidden_channels, out_channels):
        super().__init__()
        torch.manual_seed(12345)
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        self.conv3 = GCNConv(hidden_channels, out_channels)

    def forward(self, x, edge_index, batch):
        # 1. å›¾å·ç§¯å±‚
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        x = x.relu()
        x = self.conv3(x, edge_index)

        # 2. å…¨å±€æ± åŒ–ï¼ˆè·å–æ•´ä¸ªå›¾çš„è¡¨ç¤ºï¼‰
        x = global_mean_pool(x, batch)  # [batch_size, out_channels]

        # 3. åˆ†ç±»å¤´ï¼ˆç”¨äºè·¯å¾„æœ‰æ•ˆæ€§åˆ¤æ–­ï¼‰
        x = F.dropout(x, p=0.5, training=self.training)
        x = F.softmax(x, dim=1)

        return x

# æ•°æ®å‡†å¤‡ï¼šæ„å»ºæ€ç»´å›¾æ•°æ®ï¼ˆèŠ‚ç‚¹ç‰¹å¾+è¾¹ç´¢å¼•ï¼‰
def build_gnn_data(graph):
    """å°†NetworkXå›¾è½¬ä¸ºPyTorch Geometric Dataå¯¹è±¡"""
    # èŠ‚ç‚¹ç‰¹å¾ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„BERTå‘é‡ï¼ˆ768ç»´ï¼‰
    node_list = list(graph.nodes())
    node_vecs = [graph.nodes[n]['vec'] for n in node_list]
    x = torch.tensor(node_vecs, dtype=torch.float)

    # è¾¹ç´¢å¼•ï¼šNetworkXè¾¹â†’PyTorch Geometricæ ¼å¼
    edge_index = []
    for u, v in graph.edges():
        u_idx = node_list.index(u)
        v_idx = node_list.index(v)
        edge_index.append([u_idx, v_idx])
    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

    # æ ‡ç­¾ï¼šè·¯å¾„æ˜¯å¦æœ‰æ•ˆï¼ˆ1=æœ‰æ•ˆï¼Œ0=æ— æ•ˆï¼‰
    y = torch.tensor([1 if graph[u][v]['weight'] > 0.5 else 0 for u, v in graph.edges()], dtype=torch.long)

    return Data(x=x, edge_index=edge_index, y=y)

# æ¨¡å‹è®­ç»ƒ
def train_gnn(model, loader, optimizer, criterion):
    model.train()
    total_loss = 0
    for data in loader:
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
        total_loss += loss.item() * data.num_graphs
    return total_loss / len(loader.dataset)

# è·¯å¾„æ¨ç†å‡½æ•°
def infer_path(model, graph, start_node, target_node):
    """æ¨ç†ä»start_nodeåˆ°target_nodeçš„æœ‰æ•ˆè·¯å¾„"""
    # ç”Ÿæˆæ‰€æœ‰å¯èƒ½è·¯å¾„ï¼ˆæ·±åº¦â‰¤3ï¼‰
    all_paths = nx.all_simple_paths(graph, source=start_node, target=target_node, cutoff=3)
    valid_paths = []

    for path in all_paths:
        # æ„å»ºè·¯å¾„å­å›¾
        subgraph = graph.subgraph(path)
        data = build_gnn_data(subgraph)
        # æ¨¡å‹é¢„æµ‹è·¯å¾„æœ‰æ•ˆæ€§
        model.eval()
        with torch.no_grad():
            out = model(data.x, data.edge_index, torch.tensor([0]))
            pred = out.argmax(dim=1).item()
        if pred == 1:
            # è®¡ç®—è·¯å¾„æ€»åˆ†ï¼ˆè¾¹æƒé‡ä¹‹å’Œï¼‰
            path_score = sum(subgraph[u][v]['weight'] for u, v in zip(path[:-1], path[1:]))
            valid_paths.append((path, path_score))

    # æŒ‰è·¯å¾„å¾—åˆ†æ’åºï¼ˆé™åºï¼‰
    valid_paths.sort(key=lambda x: x[1], reverse=True)
    return valid_paths

11.2 GAN å¹»æƒ³å±‚ç”Ÿæˆå®Œæ•´ä»£ç 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# æ–‡æœ¬æ•°æ®é¢„å¤„ç†ï¼šå°†è¯è¯­è½¬ä¸ºç´¢å¼•
class TextDataset(Dataset):
    def __init__(self, sentences, vocab, seq_len=5):
        self.vocab = vocab
        self.seq_len = seq_len
        self.data = []
        # æ„å»ºåºåˆ—æ•°æ®ï¼ˆå¦‚â€œæˆ‘å–œæ¬¢çœ‹ä¹¦â€â†’ [æˆ‘,å–œ,æ¬¢,çœ‹] â†’ ç›®æ ‡[å–œ,æ¬¢,çœ‹,ä¹¦]ï¼‰
        for sent in sentences:
            words = jieba.lcut(sent)
            if len(words) < seq_len:
                continue
            for i in range(len(words) - seq_len + 1):
                seq = words[i:i+seq_len]
                seq_idx = [vocab.get(w, vocab['<UNK>']) for w in seq]
                self.data.append(seq_idx)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        seq = self.data[idx]
        x = torch.tensor(seq[:-1], dtype=torch.long)  # è¾“å…¥åºåˆ—
        y = torch.tensor(seq[1:], dtype=torch.long)   # ç›®æ ‡åºåˆ—
        return x, y

# GANç”Ÿæˆå™¨ï¼ˆLSTM-basedï¼‰
class Generator(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, seq_len=4):
        super().__init__()
        self.seq_len = seq_len
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, num_layers=2, dropout=0.3)
        self.fc = nn.Linear(hidden_dim, vocab_size)

    def forward(self, z):
        """z: éšæœºå™ªå£°ï¼ˆbatch_size, seq_len, embed_dimï¼‰"""
        # LSTMå‰å‘ä¼ æ’­
        out, _ = self.lstm(z)
        # è¾“å‡ºæ¯ä¸ªä½ç½®çš„è¯è¯­æ¦‚ç‡
        out = self.fc(out)
        return out

    def generate(self, vocab, start_word='<START>', num_sentences=10):
        """ç”Ÿæˆå¹»æƒ³å±‚å¥å­"""
        self.eval()
        vocab_inv = {v: k for k, v in vocab.items()}
        start_idx = vocab.get(start_word, vocab['<UNK>'])
        sentences = []

        with torch.no_grad():
            for _ in range(num_sentences):
                # åˆå§‹åŒ–è¾“å…¥ï¼ˆstart_wordï¼‰
                x = torch.tensor([[start_idx]], dtype=torch.long)
                embed_x = self.embedding(x)
                # åˆå§‹åŒ–LSTMéšè—çŠ¶æ€
                h = torch.zeros(2, 1, self.lstm.hidden_size)
                c = torch.zeros(2, 1, self.lstm.hidden_size)
                sent = [start_word]

                for _ in range(self.seq_len - 1):
                    out, (h, c) = self.lstm(embed_x, (h, c))
                    logits = self.fc(out)
                    # éšæœºé‡‡æ ·ï¼ˆå¢åŠ å¤šæ ·æ€§ï¼‰
                    probs = F.softmax(logits, dim=-1)
                    next_idx = torch.multinomial(probs[0], num_samples=1).item()
                    next_word = vocab_inv[next_idx]
                    if next_word == '<END>':
                        break
                    sent.append(next_word)
                    # æ›´æ–°è¾“å…¥
                    x = torch.tensor([[next_idx]], dtype=torch.long)
                    embed_x = self.embedding(x)

                sentences.append(''.join(sent[1:]))  # å»æ‰<START>
        return sentences

# GANåˆ¤åˆ«å™¨ï¼ˆCNN-basedï¼‰
class Discriminator(nn.Module):
    def __init__(self, vocab_size, embed_dim, seq_len=4, num_filters=64, filter_sizes=[2,3,4]):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.convs = nn.ModuleList([
            nn.Conv2d(1, num_filters, (fs, embed_dim)) for fs in filter_sizes
        ])
        self.fc = nn.Sequential(
            nn.Linear(len(filter_sizes)*num_filters, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        """x: æ–‡æœ¬åºåˆ—ï¼ˆbatch_size, seq_lenï¼‰"""
        # åµŒå…¥å±‚ï¼š(batch_size, seq_len, embed_dim)
        x = self.embedding(x).unsqueeze(1)  # å¢åŠ é€šé“ç»´åº¦ï¼š(batch_size, 1, seq_len, embed_dim)
        # å·ç§¯+æ± åŒ–
        conv_outs = []
        for conv in self.convs:
            out = conv(x)  # (batch_size, num_filters, seq_len - fs + 1, 1)
            out = F.relu(out).squeeze(-1)  # (batch_size, num_filters, seq_len - fs + 1)
            out = F.max_pool1d(out, out.size(2)).squeeze(-1)  # (batch_size, num_filters)
            conv_outs.append(out)
        # æ‹¼æ¥ç‰¹å¾
        out = torch.cat(conv_outs, dim=1)  # (batch_size, len(filter_sizes)*num_filters)
        # åˆ†ç±»
        out = self.fc(out)  # (batch_size, 1)
        return out

# GANè®­ç»ƒå‡½æ•°
def train_gan(generator, discriminator, dataloader, vocab_size, epochs=50, lr=1e-4):
    # æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    criterion = nn.BCELoss()
    opt_g = optim.AdamW(generator.parameters(), lr=lr)
    opt_d = optim.AdamW(discriminator.parameters(), lr=lr)

    # çœŸå®æ ‡ç­¾ä¸ä¼ªé€ æ ‡ç­¾
    real_label = torch.ones((dataloader.batch_size, 1))
    fake_label = torch.zeros((dataloader.batch_size, 1))

    for epoch in range(epochs):
        for i, (real_x, _) in enumerate(dataloader):
            batch_size = real_x.size(0)
            # 1. è®­ç»ƒåˆ¤åˆ«å™¨
            discriminator.zero_grad()
            # çœŸå®æ•°æ®
            real_out = discriminator(real_x)
            loss_d_real = criterion(real_out, real_label[:batch_size])
            # ä¼ªé€ æ•°æ®ï¼ˆç”Ÿæˆå™¨ç”Ÿæˆï¼‰
            z = torch.randn(batch_size, generator.seq_len, generator.embedding.embedding_dim)
            fake_x_logits = generator(z)
            fake_x = torch.argmax(fake_x_logits, dim=-1)  # è½¬ä¸ºç´¢å¼•åºåˆ—
            fake_out = discriminator(fake_x)
            loss_d_fake = criterion(fake_out, fake_label[:batch_size])
            # æ€»æŸå¤±
            loss_d = loss_d_real + loss_d_fake
            loss_d.backward()
            opt_d.step()

            # 2. è®­ç»ƒç”Ÿæˆå™¨
            generator.zero_grad()
            # ç”Ÿæˆä¼ªé€ æ•°æ®
            z = torch.randn(batch_size, generator.seq_len, generator.embedding.embedding_dim)
            fake_x_logits = generator(z)
            fake_x = torch.argmax(fake_x_logits, dim=-1)
            fake_out = discriminator(fake_x)
            # ç”Ÿæˆå™¨æŸå¤±ï¼šè®©åˆ¤åˆ«å™¨è®¤ä¸ºä¼ªé€ æ•°æ®æ˜¯çœŸå®çš„
            loss_g = criterion(fake_out, real_label[:batch_size])
            loss_g.backward()
            opt_g.step()

        # æ‰“å°è®­ç»ƒæ—¥å¿—
        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{epochs}], Loss_D: {loss_d.item():.4f}, Loss_G: {loss_g.item():.4f}")
            # ç”Ÿæˆç¤ºä¾‹å¥å­
            fake_sents = generator.generate(vocab)
            print(f"Fake Sentences Example: {fake_sents[:3]}")


ğŸ¨ æ–°å¢ç¬¬åäºŒç« ï¼šå¯è§†åŒ–ç•Œé¢è®¾è®¡ï¼ˆFlask+PyVisï¼‰
12.1 ç•Œé¢æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
æ¨¡å—åç§°
åŠŸèƒ½æè¿°
æŠ€æœ¯å®ç°
å›¾å±‚åˆ‡æ¢é¢æ¿
åˆ‡æ¢æ˜¾ç¤ºå¸¸è¯†å±‚ / è¡ç”Ÿå±‚ / å¹»æƒ³å±‚ / å…¨å›¾
PyVis å›¾å±‚æ§åˆ¶ API + HTML ä¸‹æ‹‰èœå•
èŠ‚ç‚¹æœç´¢æ¡†
æœç´¢èŠ‚ç‚¹å¹¶é«˜äº®æ˜¾ç¤º
JavaScript æœç´¢å‡½æ•° + èŠ‚ç‚¹æ ·å¼ä¿®æ”¹
è·¯å¾„æ¨ç†å·¥å…·
è¾“å…¥èµ·ç‚¹ / ç»ˆç‚¹â†’æ˜¾ç¤ºæ¨ç†è·¯å¾„
Flask åç«¯è°ƒç”¨ GNN æ¨ç†å‡½æ•°
æ‰‹åŠ¨ç¼–è¾‘åŠŸèƒ½
æ‰‹åŠ¨æ·»åŠ  / åˆ é™¤èŠ‚ç‚¹ / è¾¹
NetworkX å›¾ä¿®æ”¹ API + å‰ç«¯è¡¨å•
è¯„åˆ†è°ƒèŠ‚æ»‘å—
è°ƒèŠ‚å…¬ç”¨è¯„åˆ†æƒé‡ï¼ˆå¦‚é¢‘ç‡ / ä¿¡æ¯ç†µï¼‰
HTML æ»‘å— + åç«¯è¯„åˆ†å‡½æ•°å‚æ•°æ›´æ–°

12.2 å‰ç«¯ç•Œé¢ä»£ç ï¼ˆFlask æ¨¡æ¿ï¼‰
<!-- templates/visualization.html -->
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>å››ç»´ç¥ç»æ€ç»´å›¾å¯è§†åŒ–</title>
    <script type="text/javascript" src="https://unpkg.com/vis-network/standalone/umd/vis-network.min.js"></script>
    <style type="text/css">
        #graph-container {
            width: 100%;
            height: 700px;
            border: 1px solid #ccc;
            margin-top: 20px;
        }
        .control-panel {
            margin: 10px 0;
            padding: 10px;
            background-color: #f5f5f5;
            border-radius: 5px;
        }
        .control-group {
            margin: 10px 0;
        }
        label {
            display: inline-block;
            width: 120px;
            font-weight: bold;
        }
        input, select, button {
            padding: 5px;
            margin: 0 5px;
        }
    </style>
</head>
<body>
    <h1>å››ç»´ç¥ç»æ€ç»´å›¾ï¼ˆFD-NTGï¼‰å¯è§†åŒ–</h1>

    <!-- æ§åˆ¶é¢æ¿ -->
    <div class="control-panel">
        <!-- å›¾å±‚åˆ‡æ¢ -->
        <div class="control-group">
            <label>æ˜¾ç¤ºå›¾å±‚ï¼š</label>
            <select id="layer-select">
                <option value="all">å…¨å›¾</option>
                <option value="common">å¸¸è¯†å±‚</option>
                <option value="derive">è¡ç”Ÿå±‚</option>
                <option value="fantasy">å¹»æƒ³å±‚</option>
            </select>
            <button onclick="updateLayer()">åº”ç”¨</button>
        </div>

        <!-- èŠ‚ç‚¹æœç´¢ -->
        <div class="control-group">
            <label>æœç´¢èŠ‚ç‚¹ï¼š</label>
            <input type="text" id="node-search" placeholder="è¾“å…¥èŠ‚ç‚¹åç§°">
            <button onclick="searchNode()">æœç´¢</button>
            <button onclick="clearHighlight()">æ¸…é™¤é«˜äº®</button>
        </div>

        <!-- è·¯å¾„æ¨ç† -->
        <div class="control-group">
            <label>è·¯å¾„æ¨ç†ï¼š</label>
            <input type="text" id="start-node" placeholder="èµ·ç‚¹èŠ‚ç‚¹">
            <span>â†’</span>
            <input type="text" id="target-node" placeholder="ç»ˆç‚¹èŠ‚ç‚¹">
            <button onclick="inferPath()">æ¨ç†</button>
        </div>

        <!-- è¯„åˆ†æƒé‡è°ƒèŠ‚ -->
        <div class="control-group">
            <label>é¢‘ç‡æƒé‡ï¼š</label>
            <input type="range" id="freq-weight" min="0" max="1" step="0.1" value="0.4">
            <span id="freq-weight-val">0.4</span>
            <label>ä¿¡æ¯ç†µæƒé‡ï¼š</label>
            <input type="range" id="info-weight" min="0" max="1" step="0.1" value="0.3">
            <span id="info-weight-val">0.3</span>
            <button onclick="updateWeight()">æ›´æ–°æƒé‡</button>
        </div>
    </div>

    <!-- æ€ç»´å›¾å®¹å™¨ -->
    <div id="graph-container"></div>

    <script type="text/javascript">
        // åˆå§‹åŒ–Visç½‘ç»œ
        const container = document.getElementById('graph-container');
        const nodes = new vis.DataSet({{ nodes|safe }});  // Flaskåç«¯ä¼ é€’çš„èŠ‚ç‚¹æ•°æ®
        const edges = new vis.DataSet({{ edges|safe }});  // Flaskåç«¯ä¼ é€’çš„è¾¹æ•°æ®
        const data = { nodes: nodes, edges: edges };
        const options = {
            nodes: {
                shape: 'ellipse',
                size: 20,
                font: { size: 12 },
                color: {
                    background: {
                        common: '#8cc84b',    // å¸¸è¯†å±‚ï¼šç»¿è‰²
                        derive: '#4285f4',    // è¡ç”Ÿå±‚ï¼šè“è‰²
                        fantasy: '#ea4335'    // å¹»æƒ³å±‚ï¼šçº¢è‰²
                    }
                }
            },
            edges: {
                width: 2,
                font: { size: 10 },
                color: {
                    common: '#8cc84b',
                    derive: '#4285f4',
                    fantasy: '#ea4335',
                    causal: '#fbbc05'       // å› æœæ¡¥ï¼šé»„è‰²
                }
            },
            interaction: {
                dragNodes: true,
                zoomView: true,
                panView: true
            },
            layout: {
                hierarchical: {
                    enabled: false,
                    levelSeparation: 150
                }
            }
        };
        const network = new vis.Network(container, data, options);

        // å›¾å±‚åˆ‡æ¢å‡½æ•°
        function updateLayer() {
            const layer = document.getElementById('layer-select').value;
            if (layer === 'all') {
                nodes.update(nodes.get({ returnType: 'Object' }));  // æ˜¾ç¤ºæ‰€æœ‰èŠ‚ç‚¹
                edges.update(edges.get({ returnType: 'Object' }));  // æ˜¾ç¤ºæ‰€æœ‰è¾¹
            } else {
                // ç­›é€‰å¯¹åº”å›¾å±‚çš„èŠ‚ç‚¹å’Œè¾¹
                const layerNodes = nodes.get({
                    filter: function(node) { return node.layer === layer; }
                });
                const layerEdges = edges.get({
                    filter: function(edge) { return edge.layer === layer || edge.bridge_type === 'causal'; }
                });
                // æ›´æ–°æ˜¾ç¤º
                nodes.update(layerNodes);
                edges.update(layerEdges);
            }
        }

        // èŠ‚ç‚¹æœç´¢å‡½æ•°
        function searchNode() {
            const searchText = document.getElementById('node-search').value.trim();
            if (!searchText) return;
            // æŸ¥æ‰¾åŒ¹é…èŠ‚ç‚¹
            const matchedNodes = nodes.get({
                filter: function(node) { return node.label.includes(searchText); }
            });
            if (matchedNodes.length === 0) {
                alert('æœªæ‰¾åˆ°åŒ¹é…èŠ‚ç‚¹');
                return;
            }
            // é«˜äº®åŒ¹é…èŠ‚ç‚¹
            const nodeIds = matchedNodes.map(node => node.id);
            network.selectNodes(nodeIds);
            // èšç„¦åˆ°åŒ¹é…èŠ‚ç‚¹
            network.fit(nodeIds, { animation: true });
        }

        // æ¸…é™¤é«˜äº®
        function clearHighlight() {
            network.selectNodes([]);
            document.getElementById('node-search').value = '';
        }

        // è·¯å¾„æ¨ç†å‡½æ•°
        function inferPath() {
            const start = document.getElementById('start-node').value.trim();
            const target = document.getElementById('target-node').value.trim();
            if (!start || !target) {
                alert('è¯·è¾“å…¥èµ·ç‚¹å’Œç»ˆç‚¹èŠ‚ç‚¹');
                return;
            }
            // è°ƒç”¨Flaskåç«¯æ¨ç†æ¥å£
            fetch(`/infer_path?start=${start}&target=${target}`)
                .then(response => response.json())
                .then(data => {
                    if (data.paths.length === 0) {
                        alert('æœªæ‰¾åˆ°æœ‰æ•ˆè·¯å¾„');
                        return;
                    }
                    // é«˜äº®ç¬¬ä¸€æ¡è·¯å¾„ï¼ˆå¾—åˆ†æœ€é«˜ï¼‰
                    const topPath = data.paths[0][0];
                    const nodeIds = topPath.map(node => nodes.get({
                        filter: n => n.label === node
                    })[0].id);
                    const edgeIds = [];
                    for (let i = 0; i < topPath.length - 1; i++) {
                        const u = topPath[i];
                        const v = topPath[i+1];
                        const edge = edges.get({
                            filter: e => e.fromLabel === u && e.toLabel === v
                        })[0];
                        if (edge) edgeIds.push(edge.id);
                    }
                    // é«˜äº®è·¯å¾„
                    network.selectNodes(nodeIds);
                    network.selectEdges(edgeIds);
                    network.fit(nodeIds, { animation: true });
                    // æ˜¾ç¤ºè·¯å¾„ä¿¡æ¯
                    alert(`æ‰¾åˆ°æœ‰æ•ˆè·¯å¾„ï¼ˆå¾—åˆ†ï¼š${data.paths[0][1].toFixed(2)}ï¼‰ï¼š\n${topPath.join(' â†’ ')}`);
                })
                .catch(error => console.error('æ¨ç†é”™è¯¯ï¼š', error));
        }

        // è¯„åˆ†æƒé‡è°ƒèŠ‚
        document.getElementById('freq-weight').addEventListener('input', function() {
            document.getElementById('freq-weight-val').textContent = this.value;
        });
        document.getElementById('info-weight').addEventListener('input', function() {
            document.getElementById('info-weight-val').textContent = this.value;
        });

        function updateWeight() {
            const freqWeight = parseFloat(document.getElementById('freq-weight').value);
            const infoWeight = parseFloat(document.getElementById('info-weight').value);
            const consistencyWeight = 1 - freqWeight - infoWeight;
            if (consistencyWeight < 0) {
                alert('æƒé‡ä¹‹å’Œä¸èƒ½è¶…è¿‡1');
                return;
            }
            // è°ƒç”¨åç«¯æ›´æ–°æƒé‡
            fetch(`/update_weight?freq=${freqWeight}&info=${infoWeight}&consistency=${consistencyWeight}`)
                .then(response => response.json())
                .then(data => {
                    if (data.success) {
                        alert('æƒé‡æ›´æ–°æˆåŠŸï¼');
                        // é‡æ–°åŠ è½½å›¾ï¼ˆåº”ç”¨æ–°æƒé‡ï¼‰
                        window.location.reload();
                    } else {
                        alert('æƒé‡æ›´æ–°å¤±è´¥');
                    }
                });
        }
    </script>
</body>
</html>

12.3 Flask åç«¯å¯è§†åŒ–æ¥å£ä»£ç 
# app.pyï¼ˆFlaskå¯è§†åŒ–æœåŠ¡ï¼‰
from flask import Flask, render_template, jsonify
import networkx as nx
import json
from mind_builder import MindGraphBuilder  # å¯¼å…¥æ€ç»´å›¾æ„å»ºå™¨
from gnn_infer import infer_path  # å¯¼å…¥GNNè·¯å¾„æ¨ç†å‡½æ•°

app = Flask(__name__)

# å…¨å±€æ€ç»´å›¾å¯¹è±¡ï¼ˆåˆå§‹åŒ–ï¼‰
builder = MindGraphBuilder()
# åŠ è½½é¢„æ„å»ºçš„æ€ç»´å›¾ï¼ˆæˆ–å®æ—¶æ„å»ºï¼‰
builder.load_from_file("my_mind.mind")
global_graph = builder.final_graph  # å››ç»´ç¥ç»æ€ç»´å›¾

# å…¨å±€è¯„åˆ†æƒé‡ï¼ˆåˆå§‹å€¼ï¼‰
SCORE_WEIGHTS = {
    'freq': 0.4,
    'info': 0.3,
    'consistency': 0.3
}

# è½¬æ¢NetworkXå›¾ä¸ºVisæ ¼å¼
def nx_to_vis(graph):
    """å°†NetworkX MultiDiGraphè½¬ä¸ºVis Networkæ•°æ®æ ¼å¼"""
    nodes = []
    edges = []
    node_id_map = {}  # èŠ‚ç‚¹åç§°â†’å”¯ä¸€IDæ˜ å°„
    id_counter = 1

    # å¤„ç†èŠ‚ç‚¹
    for node, attrs in graph.nodes(data=True):
        if node not in node_id_map:
            node_id_map[node] = id_counter
            id_counter += 1
        # èŠ‚ç‚¹é¢œè‰²æ ¹æ®å›¾å±‚è®¾ç½®
        layer = attrs.get('layer', 'common')
        node_color = {
            'common': '#8cc84b',
            'derive': '#4285f4',
            'fantasy': '#ea4335'
        }[layer]
        nodes.append({
            'id': node_id_map[node],
            'label': node,
            'layer': layer,
            'color': {
                'background': node_color,
                'border': '#333'
            }
        })

    # å¤„ç†è¾¹
    for u, v, attrs in graph.edges(data=True):
        edge_id = f"{u}_{v}_{attrs.get('bridge_type', 'normal')}"
        # è¾¹é¢œè‰²æ ¹æ®å›¾å±‚æˆ–æ¡¥æ¥ç±»å‹è®¾ç½®
        layer = attrs.get('layer', 'common')
        bridge_type = attrs.get('bridge_type', 'normal')
        if bridge_type == 'causal':
            edge_color = '#fbbc05'  # å› æœæ¡¥ï¼šé»„è‰²
        else:
            edge_color = {
                'common': '#8cc84b',
                'derive': '#4285f4',
                'fantasy': '#ea4335'
            }[layer]
        edges.append({
            'id': edge_id,
            'from': node_id_map[u],
            'to': node_id_map[v],
            'label': f"{attrs.get('weight', 0.0):.2f}",
            'layer': layer,
            'bridge_type': bridge_type,
            'color': edge_color,
            'fromLabel': u,  # å­˜å‚¨åŸå§‹èŠ‚ç‚¹åç§°ï¼Œç”¨äºè·¯å¾„æ¨ç†
            'toLabel': v
        })

    return {'nodes': nodes, 'edges': edges}, node_id_map

# å¯è§†åŒ–ä¸»é¡µ
@app.route('/')
def visualize():
    vis_data, _ = nx_to_vis(global_graph)
    # å°†æ•°æ®è½¬ä¸ºJSONæ ¼å¼ä¼ é€’ç»™å‰ç«¯
    nodes_json = json.dumps(vis_data['nodes'])
    edges_json = json.dumps(vis_data['edges'])
    return render_template('visualization.html', nodes=nodes_json, edges=edges_json)

# è·¯å¾„æ¨ç†æ¥å£
@app.route('/infer_path')
def infer_path_api():
    start = request.args.get('start')
    target = request.args.get('target')
    if not start or not target:
        return jsonify({'paths': [], 'error': 'ç¼ºå°‘èµ·ç‚¹æˆ–ç»ˆç‚¹'})
    # è°ƒç”¨GNNè·¯å¾„æ¨ç†å‡½æ•°
    paths = infer_path(global_graph, start, target)
    return jsonify({'paths': paths})

# è¯„åˆ†æƒé‡æ›´æ–°æ¥å£
@app.route('/update_weight')
def update_weight_api():
    global SCORE_WEIGHTS
    freq = float(request.args.get('freq', 0.4))
    info = float(request.args.get('info', 0.3))
    consistency = float(request.args.get('consistency', 0.3))
    # éªŒè¯æƒé‡ä¹‹å’Œä¸º1
    if abs(freq + info + consistency - 1) > 1e-6:
        return jsonify({'success': False, 'error': 'æƒé‡ä¹‹å’Œå¿…é¡»ä¸º1'})
    # æ›´æ–°å…¨å±€æƒé‡
    SCORE_WEIGHTS = {
        'freq': freq,
        'info': info,
        'consistency': consistency
    }
    # æ›´æ–°æ€ç»´å›¾ä¸­çš„è¯„åˆ†æœºåˆ¶
    builder.update_scorer_weights(SCORE_WEIGHTS)
    return jsonify({'success': True})

if __name__ == '__main__':
    app.run(debug=True, port=5000)


âœ… æ–°å¢ç¬¬åä¸‰ç« ï¼šè¡¥å……ç»“è®ºä¸å±•æœ›
13.1 è¡¥å……ç»“è®º
æœ¬è¡¥å……æŠ¥å‘Šé€šè¿‡å®éªŒéªŒè¯ã€å¤šæ¨¡æ€æ‰©å±•ã€æ€ç»´ç½‘ OS è®¾è®¡ã€æ ¸å¿ƒä»£ç å®Œå–„åŠå¯è§†åŒ–ç•Œé¢å¼€å‘ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†ã€Œå››ç»´ç¥ç»æ€ç»´å›¾ç³»ç»Ÿã€çš„å¯è¡Œæ€§ä¸ä¼˜åŠ¿ï¼š
å®éªŒæ•°æ®æ”¯æ’‘ï¼šåœ¨å¯è§£é‡Šæ€§ã€å¯æ§æ€§ã€è½»é‡æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¸»æµå¤§æ¨¡å‹ï¼Œé¢†åŸŸé€‚é…èƒ½åŠ›å¼ºï¼ˆå¦‚æ•™è‚²åœºæ™¯å‡†ç¡®ç‡ 94%ï¼‰
å¤šæ¨¡æ€æ‰©å±•è½åœ°ï¼šå®ç°å›¾åƒ / éŸ³é¢‘ / è§†é¢‘ä¸æ–‡æœ¬çš„è·¨æ¨¡æ€èåˆï¼Œæ„å»ºäº†ç»Ÿä¸€çš„è®¤çŸ¥è¡¨ç¤ºæ¡†æ¶
å·¥ç¨‹åŒ–èƒ½åŠ›å®Œå–„ï¼šæä¾›å®Œæ•´çš„ GNN æ¨ç†ã€GAN ç”Ÿæˆä»£ç ï¼ŒåŠå¯äº¤äº’çš„å¯è§†åŒ–ç•Œé¢ï¼Œæ”¯æŒç”¨æˆ·æ‰‹åŠ¨å¹²é¢„ä¸æƒé‡è°ƒèŠ‚
ç”Ÿæ€åŒ–æ–¹å‘æ˜ç¡®ï¼šæ€ç»´ç½‘ OS æ¶æ„ä¸ºåç»­å¤šç”¨æˆ·ååŒã€ç¬¬ä¸‰æ–¹æ’ä»¶æ‰©å±•å¥ å®šåŸºç¡€ï¼Œå…·å¤‡ä» â€œå·¥å…·â€ å‘ â€œå¹³å°â€ æ¼”è¿›çš„æ½œåŠ›
13.2 æ·±åŒ–å±•æœ›
è®¤çŸ¥è¿›åŒ–æœºåˆ¶ï¼šå¼•å…¥ â€œæ€ç»´å›¾çªå˜â€ ç®—æ³•ï¼ˆå¦‚åŸºäºé—ä¼ ç®—æ³•çš„èŠ‚ç‚¹ / è¾¹å˜å¼‚ï¼‰ï¼Œå®ç°ç³»ç»Ÿè‡ªä¸»çŸ¥è¯†æ›´æ–°
è·¨è¯­è¨€æ‰©å±•ï¼šæ”¯æŒä¸­è‹±æ–‡åŒè¯­èŠ‚ç‚¹ï¼Œæ„å»ºè·¨è¯­è¨€å› æœæ¡¥ï¼ˆå¦‚ â€œçŒ«â€â†’â€œcatâ€ï¼‰ï¼Œå®ç°å¤šè¯­è¨€è®¤çŸ¥ç»Ÿä¸€
è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼šé’ˆå¯¹åµŒå…¥å¼è®¾å¤‡ï¼ˆå¦‚æ ‘è“æ´¾ï¼‰ä¼˜åŒ–æ¨¡å‹ï¼Œå®ç°ç«¯ä¾§è½»é‡åŒ–æ¨ç†ï¼ˆå†…å­˜â‰¤512MBï¼‰
äººæœºååŒè®­ç»ƒï¼šè®¾è®¡ç”¨æˆ·åé¦ˆå¥–åŠ±æœºåˆ¶ï¼ˆå¦‚ç”¨æˆ·æ ‡è®° â€œæœ‰æ•ˆè·¯å¾„â€ ç»™äºˆ RL æ­£å¥–åŠ±ï¼‰ï¼Œæå‡ç³»ç»Ÿè®¤çŸ¥ç²¾åº¦
è¡Œä¸šè§£å†³æ–¹æ¡ˆï¼šå¼€å‘å‚ç›´é¢†åŸŸå¥—ä»¶ï¼ˆå¦‚åŒ»ç–—ç‰ˆï¼šå¸¸è¯†å±‚åŒ…å«ç–¾ç—…è¯Šæ–­è§„åˆ™ï¼Œè¡ç”Ÿå±‚æ”¯æŒç—…å†æ¨ç†ï¼›å·¥ä¸šç‰ˆï¼šå¸¸è¯†å±‚åŒ…å«è®¾å¤‡å‚æ•°ï¼Œè¡ç”Ÿå±‚æ”¯æŒæ•…éšœé¢„æµ‹ï¼‰

<img width="2841" height="2131" alt="æœªå‘½åç»˜å›¾ drawio" src="https://github.com/user-attachments/assets/f9ce9929-f97b-421b-bc7a-aead04e8d9b9" />
<img width="1080" height="1440" alt="1760271033980" src="https://github.com/user-attachments/assets/4bc9ec97-0dcd-4373-a26a-eef5fb071498" />
<img width="1540" height="1404" alt="image (1)" src="https://github.com/user-attachments/assets/8aabd30d-394f-4f49-b6e0-7fc76b4bb559" />
<img width="2484" height="2164" alt="image" src="https://github.com/user-attachments/assets/0ff9749e-7c5e-4f0b-9494-b6ad005542ac" />
<img width="1080" height="1440" alt="1760271038578" src="https://github.com/user-attachments/assets/756138ed-50cf-43ef-872a-8d32e9ac02e5" />
<img width="1007" height="773" alt="å±å¹•æˆªå›¾ 2025-10-11 211723" src="https://github.com/user-attachments/assets/c4de9c20-f57a-4835-81d4-320c75db1ed5" />
<img width="951" height="692" alt="å±å¹•æˆªå›¾ 2025-10-11 211056" src="https://github.com/user-attachments/assets/f233d0d4-b0ac-4f2a-a5b6-05ab7940b7d8" />
<img width="1659" height="1144" alt="å±å¹•æˆªå›¾ 2025-10-11 164817" src="https://github.com/user-attachments/assets/dc95e1a8-9356-4ab9-9483-237e30b2f951" />
<img width="2554" height="1373" alt="å±å¹•æˆªå›¾ 2025-10-11 164757" src="https://github.com/user-attachments/assets/472fe5e7-2f53-44c7-96b0-30846e74d177" />
<img width="1781" height="1006" alt="å±å¹•æˆªå›¾ 2025-10-11 035451" src="https://github.com/user-attachments/assets/1a9faabb-64d1-4ac7-ba09-b05976a2499b" />
<img width="2552" height="1357" alt="å±å¹•æˆªå›¾ 2025-10-11 025625" src="https://github.com/user-attachments/assets/a7ddba92-600a-40d5-8e24-d38d2ad0ec0e" />
<img width="1144" height="1110" alt="å±å¹•æˆªå›¾ 2025-10-11 011622" src="https://github.com/user-attachments/assets/63577a49-f3c5-451b-bd28-4a861a22c2e1" />
<img width="899" height="1100" alt="å±å¹•æˆªå›¾ 2025-10-11 005420" src="https://github.com/user-attachments/assets/e4ca4d68-8e38-4e99-801b-86f3bbc7839b" />
<img width="887" height="1120" alt="å±å¹•æˆªå›¾ 2025-10-11 005409" src="https://github.com/user-attachments/assets/2faef6f5-9146-47f9-82f8-c6dedc75da7c" />
